{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cuJHRzP8sfXZ"
      },
      "source": [
        "# Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "irZfL99X4VZ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import html\n",
        "import string\n",
        "\n",
        "import lightgbm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iGRMWuX2sCjl"
      },
      "source": [
        "# Очистка трейна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wHBMSSNSvNL"
      },
      "outputs": [],
      "source": [
        "# data_train = pd.read_json('ranking_train.jsonl', lines=True)\n",
        "# new_rows = []\n",
        "# for index, row in data_train.iterrows():\n",
        "#     new_row = {'text': row['text']}\n",
        "#     for i in range(len(row['comments'])):\n",
        "#         new_row['comments_text_' + str(i)] = row['comments'][i]['text']\n",
        "#     new_rows.append(new_row)\n",
        "\n",
        "# pd.DataFrame(new_rows).to_csv('ranking_train.tsv', sep=\"\\t\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "P4PoBVLOSwUS",
        "outputId": "c0a0e3f6-bc09-4f5a-d122-d3859dc6ba99"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e3261a0d-662f-48f7-b575-f4b5eeeae6e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>comments_text_0</th>\n",
              "      <th>comments_text_1</th>\n",
              "      <th>comments_text_2</th>\n",
              "      <th>comments_text_3</th>\n",
              "      <th>comments_text_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>Going back to school is not identical with giv...</td>\n",
              "      <td>There will invariably be those who don't see t...</td>\n",
              "      <td>For me school is a way to be connected to what...</td>\n",
              "      <td>I guess it really depends on how hungry you ar...</td>\n",
              "      <td>I know pollground decided to go back to school...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CBS acquires last.fm for $280m</td>\n",
              "      <td>It will be curious to see where this heads in ...</td>\n",
              "      <td>Does this mean that there's now a big-name com...</td>\n",
              "      <td>Also on BBC News:   &lt;url&gt;  .Nice to see a Lond...</td>\n",
              "      <td>I don't understand what they do that is worth ...</td>\n",
              "      <td>sold out too cheaply. given their leadership p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How Costco Became the Anti-Wal-Mart</td>\n",
              "      <td>I really hate it when people falsely claim tha...</td>\n",
              "      <td>I love Costco.  For me, the best quote of the ...</td>\n",
              "      <td>\"But Mr. Sinegal warned that if Costco increas...</td>\n",
              "      <td>While Costco does treat its employees a little...</td>\n",
              "      <td>I'd like to know more about their \"don't adver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fortune Favors Big Turds | Screw The Money, Th...</td>\n",
              "      <td>His real point is that something can be \"simpl...</td>\n",
              "      <td>So I'm thinking, \"Well, I've never heard of th...</td>\n",
              "      <td>I've never seen a single blog post wander in s...</td>\n",
              "      <td>It was a RANT on a personal blog. It's there t...</td>\n",
              "      <td>In the eternal words of the Geico Caveman..\"Wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>StartupWeekend: 70 Founders Create One Company...</td>\n",
              "      <td>Looks like someone hasn't read The Mythical Ma...</td>\n",
              "      <td>Any chances for recreating this in a telecommu...</td>\n",
              "      <td>You know, if they started with 70 and eliminat...</td>\n",
              "      <td>And what did you do this weekend?I'd love to h...</td>\n",
              "      <td>Very interesting. I would join an event like t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Younger job seekers hold the advantage (becaus...</td>\n",
              "      <td>I smell bullshit. Note from the article:&gt; Comp...</td>\n",
              "      <td>Not a bad read, although I wonder what reality...</td>\n",
              "      <td>More than anything, I think this is about all ...</td>\n",
              "      <td>Some even have their parents in the room for a...</td>\n",
              "      <td>One thing that bugs me about SlapVid is that i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Four Pownce Invites</td>\n",
              "      <td>Ok these are out the door.  I have a few more ...</td>\n",
              "      <td>sgoraya at gmail.com\\nthx!</td>\n",
              "      <td>&lt;email&gt; .</td>\n",
              "      <td>&lt;email&gt; Thanks.</td>\n",
              "      <td>kyle.bolton at gmail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LFMs and LFSPs (Michael Vanier via PG)</td>\n",
              "      <td>I'd forgotten how well written that was.  It's...</td>\n",
              "      <td>Perfection is achieved, not when there is noth...</td>\n",
              "      <td>To get wider use of LFSPs, it would be importa...</td>\n",
              "      <td>I totally understand people's complaints about...</td>\n",
              "      <td>for (i = 0; i &lt; N; i++)Odd example to use. It'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The Virtues of a Second Screen</td>\n",
              "      <td>I guess I'm one of the few people who has trie...</td>\n",
              "      <td>I didn't look at the date, but when I saw the ...</td>\n",
              "      <td>I am a big believer in 2 screens as well.  I h...</td>\n",
              "      <td>Bah. A 30\" is vastly superior to two screens. ...</td>\n",
              "      <td>Why is it posted here?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Startup Weekend failed, but lessons learned</td>\n",
              "      <td>70 days and 2 people would work much better th...</td>\n",
              "      <td>They learned a lesson indeed: \"Development is ...</td>\n",
              "      <td>Is anyone else confused by the premise of star...</td>\n",
              "      <td>&gt; The Java platform was selected/Nuff\\n</td>\n",
              "      <td>This is the first I'd heard of startupweekend....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3261a0d-662f-48f7-b575-f4b5eeeae6e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3261a0d-662f-48f7-b575-f4b5eeeae6e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3261a0d-662f-48f7-b575-f4b5eeeae6e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  How many summer Y Combinator fundees decided n...   \n",
              "1                     CBS acquires last.fm for $280m   \n",
              "2                How Costco Became the Anti-Wal-Mart   \n",
              "3  Fortune Favors Big Turds | Screw The Money, Th...   \n",
              "4  StartupWeekend: 70 Founders Create One Company...   \n",
              "5  Younger job seekers hold the advantage (becaus...   \n",
              "6                                Four Pownce Invites   \n",
              "7             LFMs and LFSPs (Michael Vanier via PG)   \n",
              "8                     The Virtues of a Second Screen   \n",
              "9        Startup Weekend failed, but lessons learned   \n",
              "\n",
              "                                     comments_text_0  \\\n",
              "0  Going back to school is not identical with giv...   \n",
              "1  It will be curious to see where this heads in ...   \n",
              "2  I really hate it when people falsely claim tha...   \n",
              "3  His real point is that something can be \"simpl...   \n",
              "4  Looks like someone hasn't read The Mythical Ma...   \n",
              "5  I smell bullshit. Note from the article:> Comp...   \n",
              "6  Ok these are out the door.  I have a few more ...   \n",
              "7  I'd forgotten how well written that was.  It's...   \n",
              "8  I guess I'm one of the few people who has trie...   \n",
              "9  70 days and 2 people would work much better th...   \n",
              "\n",
              "                                     comments_text_1  \\\n",
              "0  There will invariably be those who don't see t...   \n",
              "1  Does this mean that there's now a big-name com...   \n",
              "2  I love Costco.  For me, the best quote of the ...   \n",
              "3  So I'm thinking, \"Well, I've never heard of th...   \n",
              "4  Any chances for recreating this in a telecommu...   \n",
              "5  Not a bad read, although I wonder what reality...   \n",
              "6                         sgoraya at gmail.com\\nthx!   \n",
              "7  Perfection is achieved, not when there is noth...   \n",
              "8  I didn't look at the date, but when I saw the ...   \n",
              "9  They learned a lesson indeed: \"Development is ...   \n",
              "\n",
              "                                     comments_text_2  \\\n",
              "0  For me school is a way to be connected to what...   \n",
              "1  Also on BBC News:   <url>  .Nice to see a Lond...   \n",
              "2  \"But Mr. Sinegal warned that if Costco increas...   \n",
              "3  I've never seen a single blog post wander in s...   \n",
              "4  You know, if they started with 70 and eliminat...   \n",
              "5  More than anything, I think this is about all ...   \n",
              "6                                          <email> .   \n",
              "7  To get wider use of LFSPs, it would be importa...   \n",
              "8  I am a big believer in 2 screens as well.  I h...   \n",
              "9  Is anyone else confused by the premise of star...   \n",
              "\n",
              "                                     comments_text_3  \\\n",
              "0  I guess it really depends on how hungry you ar...   \n",
              "1  I don't understand what they do that is worth ...   \n",
              "2  While Costco does treat its employees a little...   \n",
              "3  It was a RANT on a personal blog. It's there t...   \n",
              "4  And what did you do this weekend?I'd love to h...   \n",
              "5  Some even have their parents in the room for a...   \n",
              "6                                    <email> Thanks.   \n",
              "7  I totally understand people's complaints about...   \n",
              "8  Bah. A 30\" is vastly superior to two screens. ...   \n",
              "9            > The Java platform was selected/Nuff\\n   \n",
              "\n",
              "                                     comments_text_4  \n",
              "0  I know pollground decided to go back to school...  \n",
              "1  sold out too cheaply. given their leadership p...  \n",
              "2  I'd like to know more about their \"don't adver...  \n",
              "3  In the eternal words of the Geico Caveman..\"Wh...  \n",
              "4  Very interesting. I would join an event like t...  \n",
              "5  One thing that bugs me about SlapVid is that i...  \n",
              "6                               kyle.bolton at gmail  \n",
              "7  for (i = 0; i < N; i++)Odd example to use. It'...  \n",
              "8                            Why is it posted here?   \n",
              "9  This is the first I'd heard of startupweekend....  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_data_tsv = pd.read_csv('ranking_train.tsv', sep=\"\\t\")\n",
        "# train_data_tsv[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CKuNKsvD4ty7"
      },
      "outputs": [],
      "source": [
        "data = pd.read_json('ranking_train.jsonl', lines=True)\n",
        "new_rows = []\n",
        "for index, row in data.iterrows():\n",
        "    for comment in row['comments']:\n",
        "        new_row = {'text': row['text'], 'comments_text': comment['text'], 'comments_score': comment['score']}\n",
        "        new_rows.append(new_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Q2V8TTOX4v2t",
        "outputId": "d5457eb1-aec7-45f8-e284-aa4bcd3c2e76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-30735289-103d-4cda-bcfa-5d216c494971\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>comments_text</th>\n",
              "      <th>comments_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>Going back to school is not identical with giv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>There will invariably be those who don't see t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>For me school is a way to be connected to what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>I guess it really depends on how hungry you ar...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How many summer Y Combinator fundees decided n...</td>\n",
              "      <td>I know pollground decided to go back to school...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440530</th>\n",
              "      <td>Pay your rent with a Credit or Debit card. No ...</td>\n",
              "      <td>Most major banks offer a service called &amp;#x27;...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440531</th>\n",
              "      <td>Pay your rent with a Credit or Debit card. No ...</td>\n",
              "      <td>It costs 3.25%, or $74.25 for the example of $...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440532</th>\n",
              "      <td>Pay your rent with a Credit or Debit card. No ...</td>\n",
              "      <td>As many other comments have pointed out almost...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440533</th>\n",
              "      <td>Pay your rent with a Credit or Debit card. No ...</td>\n",
              "      <td>My apartment building uses Yapstone&amp;#x27;s Ren...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440534</th>\n",
              "      <td>Pay your rent with a Credit or Debit card. No ...</td>\n",
              "      <td>Video seems in poor taste.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>440535 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30735289-103d-4cda-bcfa-5d216c494971')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30735289-103d-4cda-bcfa-5d216c494971 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30735289-103d-4cda-bcfa-5d216c494971');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                     text  \\\n",
              "0       How many summer Y Combinator fundees decided n...   \n",
              "1       How many summer Y Combinator fundees decided n...   \n",
              "2       How many summer Y Combinator fundees decided n...   \n",
              "3       How many summer Y Combinator fundees decided n...   \n",
              "4       How many summer Y Combinator fundees decided n...   \n",
              "...                                                   ...   \n",
              "440530  Pay your rent with a Credit or Debit card. No ...   \n",
              "440531  Pay your rent with a Credit or Debit card. No ...   \n",
              "440532  Pay your rent with a Credit or Debit card. No ...   \n",
              "440533  Pay your rent with a Credit or Debit card. No ...   \n",
              "440534  Pay your rent with a Credit or Debit card. No ...   \n",
              "\n",
              "                                            comments_text  comments_score  \n",
              "0       Going back to school is not identical with giv...               0  \n",
              "1       There will invariably be those who don't see t...               1  \n",
              "2       For me school is a way to be connected to what...               2  \n",
              "3       I guess it really depends on how hungry you ar...               3  \n",
              "4       I know pollground decided to go back to school...               4  \n",
              "...                                                   ...             ...  \n",
              "440530  Most major banks offer a service called &#x27;...               0  \n",
              "440531  It costs 3.25%, or $74.25 for the example of $...               1  \n",
              "440532  As many other comments have pointed out almost...               2  \n",
              "440533  My apartment building uses Yapstone&#x27;s Ren...               3  \n",
              "440534                         Video seems in poor taste.               4  \n",
              "\n",
              "[440535 rows x 3 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.DataFrame(new_rows)\n",
        "data = data.reset_index(drop=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3-IBnAZNS0Fc"
      },
      "outputs": [],
      "source": [
        "def preprocessing(data):\n",
        "\n",
        "    for column in data.columns:\n",
        "        #заменяем коды на символы\n",
        "        data[column] = data[column].apply(html.unescape)\n",
        "\n",
        "        #заменяем url'ы на токен 1url1\n",
        "        data[column] = data[column].str.replace(\n",
        "        r\"(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\",\n",
        "        '1url1',\n",
        "        regex=True)\n",
        "\n",
        "        #заменяем email'ы на токен 1email1\n",
        "        data[column] = data[column].str.replace(\n",
        "            r\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*)@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\",\n",
        "            '1email1',\n",
        "            regex=True)\n",
        "\n",
        "        #убираем ссылки\n",
        "        data[column] = data[column].str.replace(r'\\[\\d\\]', '', regex=True)\n",
        "\n",
        "        # #понижаем регистр\n",
        "        data[column] = data[column].apply(lambda x: x.lower())\n",
        "\n",
        "        #избавляемся от лишних знаков пунктуации\n",
        "        data[column] = data[column].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation + \"\\n\")))\n",
        "\n",
        "        #делаем обратную замену на <token>\n",
        "        data[column] = data[column].str.replace('1url1', ' <url> ')\n",
        "        data[column] = data[column].str.replace('1email1', ' <email> ')\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sK6Ho8AkWuXq",
        "outputId": "fd369c2b-0ee2-4996-b3f8-3523f0c390f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-04a5bb73-6f48-4fc9-8612-2177777fea65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>comments_text</th>\n",
              "      <th>comments_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how many summer y combinator fundees decided n...</td>\n",
              "      <td>going back to school is not identical with giv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how many summer y combinator fundees decided n...</td>\n",
              "      <td>there will invariably be those who dont see th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how many summer y combinator fundees decided n...</td>\n",
              "      <td>for me school is a way to be connected to what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how many summer y combinator fundees decided n...</td>\n",
              "      <td>i guess it really depends on how hungry you ar...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how many summer y combinator fundees decided n...</td>\n",
              "      <td>i know pollground decided to go back to school...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440530</th>\n",
              "      <td>pay your rent with a credit or debit card no l...</td>\n",
              "      <td>most major banks offer a service called bill p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440531</th>\n",
              "      <td>pay your rent with a credit or debit card no l...</td>\n",
              "      <td>it costs 325 or 7425 for the example of 2300 s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440532</th>\n",
              "      <td>pay your rent with a credit or debit card no l...</td>\n",
              "      <td>as many other comments have pointed out almost...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440533</th>\n",
              "      <td>pay your rent with a credit or debit card no l...</td>\n",
              "      <td>my apartment building uses yapstones rentpayme...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440534</th>\n",
              "      <td>pay your rent with a credit or debit card no l...</td>\n",
              "      <td>video seems in poor taste</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>440535 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04a5bb73-6f48-4fc9-8612-2177777fea65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04a5bb73-6f48-4fc9-8612-2177777fea65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04a5bb73-6f48-4fc9-8612-2177777fea65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                     text  \\\n",
              "0       how many summer y combinator fundees decided n...   \n",
              "1       how many summer y combinator fundees decided n...   \n",
              "2       how many summer y combinator fundees decided n...   \n",
              "3       how many summer y combinator fundees decided n...   \n",
              "4       how many summer y combinator fundees decided n...   \n",
              "...                                                   ...   \n",
              "440530  pay your rent with a credit or debit card no l...   \n",
              "440531  pay your rent with a credit or debit card no l...   \n",
              "440532  pay your rent with a credit or debit card no l...   \n",
              "440533  pay your rent with a credit or debit card no l...   \n",
              "440534  pay your rent with a credit or debit card no l...   \n",
              "\n",
              "                                            comments_text  comments_score  \n",
              "0       going back to school is not identical with giv...               0  \n",
              "1       there will invariably be those who dont see th...               1  \n",
              "2       for me school is a way to be connected to what...               2  \n",
              "3       i guess it really depends on how hungry you ar...               3  \n",
              "4       i know pollground decided to go back to school...               4  \n",
              "...                                                   ...             ...  \n",
              "440530  most major banks offer a service called bill p...               0  \n",
              "440531  it costs 325 or 7425 for the example of 2300 s...               1  \n",
              "440532  as many other comments have pointed out almost...               2  \n",
              "440533  my apartment building uses yapstones rentpayme...               3  \n",
              "440534                          video seems in poor taste               4  \n",
              "\n",
              "[440535 rows x 3 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.iloc[:, :2] = preprocessing(data.iloc[:, :2])\n",
        "data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j34TBqOebmvq"
      },
      "source": [
        "# Train-Val Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "u2CnJXtu410r"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "splitter = GroupShuffleSplit(test_size=0.2, n_splits=2, random_state=42)\n",
        "split = splitter.split(data, groups=data['text'])\n",
        "train_inds, val_inds = next(split)\n",
        "\n",
        "train = data.iloc[train_inds]\n",
        "val = data.iloc[val_inds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Y_nyf-wG8l1q"
      },
      "outputs": [],
      "source": [
        "X_train_raw = train['text'] + train['comments_text']\n",
        "y_train = np.array(train['comments_score'])\n",
        "\n",
        "X_val_raw = val['text'] + val['comments_text']\n",
        "y_val = np.array(val['comments_score'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vTcihWoNsKLZ"
      },
      "source": [
        "# Векторизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRSsaZoebfCg",
        "outputId": "0b752348-f550-40f8-9af4-d1ec23f0f18e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import gensim.downloader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "gi0iXYgebyZt"
      },
      "outputs": [],
      "source": [
        "import vector_space_models_utils\n",
        "from vector_space_models_utils import rank_comments\n",
        "from vector_space_models_utils import Embeddings_text_to_vector\n",
        "from vector_space_models_utils import get_predicted_order\n",
        "from vector_space_models_utils import hits_score\n",
        "from vector_space_models_utils import dcg_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "v3wjthTdb5CK"
      },
      "outputs": [],
      "source": [
        "stopWords = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "v-hYvROHcD1E"
      },
      "outputs": [],
      "source": [
        "class NLTK_Tokenizer:\n",
        "    def __init__(self, delete_punctuation=False, delete_stop_words=False):\n",
        "        self.delete_punctuation = delete_punctuation\n",
        "        self.delete_stop_words = delete_stop_words\n",
        "    def tokenize(self, text, ):\n",
        "        if self.delete_punctuation:\n",
        "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        if self.delete_stop_words:\n",
        "            return [token for token in tokens if token not in stopWords]\n",
        "        return tokens\n",
        "\n",
        "nltk_tokenizer = NLTK_Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "gK1d2_UjeNSZ"
      },
      "outputs": [],
      "source": [
        "embeddings_list = [('glove-wiki-gigaword-50', 50),\n",
        "                   ('glove-wiki-gigaword-100', 100),\n",
        "                   ('glove-wiki-gigaword-200', 200),\n",
        "                   ('glove-twitter-25', 25),\n",
        "                   ('glove-twitter-50', 50),\n",
        "                   ('glove-twitter-100', 100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "aJNEWKLFrAVX"
      },
      "outputs": [],
      "source": [
        "def text_to_vec(text, embeddings, tokenizer, dim=200, aggregation='mean', verbose=False):\n",
        "    \"\"\"\n",
        "        text: строка\n",
        "        embeddings: наше векторное представление\n",
        "        dim: размер любого вектора в нашем представлении\n",
        "\n",
        "        return: векторное представление для вопроса\n",
        "    \"\"\"\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    result = np.zeros(dim)\n",
        "\n",
        "    if verbose:\n",
        "        print('Initial text:', text)\n",
        "        print('Tokens:', tokens)\n",
        "\n",
        "    if aggregation == 'mean':\n",
        "        iterator = 0\n",
        "\n",
        "        for word in tokens:\n",
        "            if word in embeddings:\n",
        "                result += embeddings[word]\n",
        "                iterator += 1\n",
        "                if verbose and dim > 5:\n",
        "                    print('Word and its embedding:', word, embeddings[word][:5])\n",
        "\n",
        "        if iterator != 0:\n",
        "            result = result / iterator\n",
        "    else:\n",
        "        raise AttributeError(f'No aggregation type {aggregation}, please, use other')\n",
        "\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "GcAJl4iYiWDe"
      },
      "outputs": [],
      "source": [
        "def transform_data(embeddings, y, vector_dim):\n",
        "    idx = []\n",
        "    for i in range(int(len(embeddings) / 5)):\n",
        "        idx.extend([i] * 5)\n",
        "\n",
        "    embeddings_df = pd.DataFrame(embeddings, columns=[i for i in range(1, vector_dim+1)])\n",
        "    embeddings_df['score'] = y\n",
        "    embeddings_df['qid'] = idx\n",
        "\n",
        "    qids = embeddings_df.groupby('qid')['qid'].count().to_numpy()\n",
        "    X = embeddings_df.drop(['score', 'qid'], axis = 1)\n",
        "    #y = embeddings_df['score'].astype(int)\n",
        "\n",
        "    return X, qids"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1X7r9FjDfG3U"
      },
      "source": [
        "# Сравнение различных эмбеддингов на LambdaMART модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyCU54FSfFZy",
        "outputId": "d52ced37-8fe0-4b9b-fb6d-f5d1b076f950"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "glove-wiki-gigaword-50\n",
            "\n",
            "[1]\tvalid_0's ndcg@1: 0.453291\tvalid_0's ndcg@3: 0.576642\tvalid_0's ndcg@5: 0.784891\n",
            "[2]\tvalid_0's ndcg@1: 0.556738\tvalid_0's ndcg@3: 0.656875\tvalid_0's ndcg@5: 0.825513\n",
            "[3]\tvalid_0's ndcg@1: 0.58817\tvalid_0's ndcg@3: 0.680489\tvalid_0's ndcg@5: 0.83778\n",
            "[4]\tvalid_0's ndcg@1: 0.601589\tvalid_0's ndcg@3: 0.694311\tvalid_0's ndcg@5: 0.843943\n",
            "[5]\tvalid_0's ndcg@1: 0.609617\tvalid_0's ndcg@3: 0.700847\tvalid_0's ndcg@5: 0.847255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 1/6 [05:51<29:18, 351.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "glove-wiki-gigaword-100\n",
            "\n",
            "[1]\tvalid_0's ndcg@1: 0.451844\tvalid_0's ndcg@3: 0.578905\tvalid_0's ndcg@5: 0.785632\n",
            "[2]\tvalid_0's ndcg@1: 0.564936\tvalid_0's ndcg@3: 0.665218\tvalid_0's ndcg@5: 0.82949\n",
            "[3]\tvalid_0's ndcg@1: 0.597943\tvalid_0's ndcg@3: 0.690997\tvalid_0's ndcg@5: 0.842469\n",
            "[4]\tvalid_0's ndcg@1: 0.608823\tvalid_0's ndcg@3: 0.700837\tvalid_0's ndcg@5: 0.847122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 2/6 [12:34<25:27, 381.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.617149\tvalid_0's ndcg@3: 0.707373\tvalid_0's ndcg@5: 0.850276\n",
            "\n",
            "\n",
            "glove-wiki-gigaword-200\n",
            "\n",
            "[1]\tvalid_0's ndcg@1: 0.450397\tvalid_0's ndcg@3: 0.583718\tvalid_0's ndcg@5: 0.786575\n",
            "[2]\tvalid_0's ndcg@1: 0.569362\tvalid_0's ndcg@3: 0.666479\tvalid_0's ndcg@5: 0.830534\n",
            "[3]\tvalid_0's ndcg@1: 0.60773\tvalid_0's ndcg@3: 0.694624\tvalid_0's ndcg@5: 0.844981\n",
            "[4]\tvalid_0's ndcg@1: 0.624128\tvalid_0's ndcg@3: 0.708904\tvalid_0's ndcg@5: 0.851969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 3/6 [21:04<22:01, 440.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.627759\tvalid_0's ndcg@3: 0.714537\tvalid_0's ndcg@5: 0.854429\n",
            "\n",
            "\n",
            "glove-twitter-25\n",
            "\n",
            "[1]\tvalid_0's ndcg@1: 0.459844\tvalid_0's ndcg@3: 0.568761\tvalid_0's ndcg@5: 0.78393\n",
            "[2]\tvalid_0's ndcg@1: 0.544638\tvalid_0's ndcg@3: 0.635997\tvalid_0's ndcg@5: 0.817476\n",
            "[3]\tvalid_0's ndcg@1: 0.566638\tvalid_0's ndcg@3: 0.666379\tvalid_0's ndcg@5: 0.830066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 4/6 [27:01<13:34, 407.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4]\tvalid_0's ndcg@1: 0.585589\tvalid_0's ndcg@3: 0.677775\tvalid_0's ndcg@5: 0.83635\n",
            "[5]\tvalid_0's ndcg@1: 0.59322\tvalid_0's ndcg@3: 0.685552\tvalid_0's ndcg@5: 0.839962\n",
            "\n",
            "\n",
            "glove-twitter-50\n",
            "\n",
            "[1]\tvalid_0's ndcg@1: 0.460823\tvalid_0's ndcg@3: 0.571338\tvalid_0's ndcg@5: 0.784834\n",
            "[2]\tvalid_0's ndcg@1: 0.564071\tvalid_0's ndcg@3: 0.656135\tvalid_0's ndcg@5: 0.826406\n",
            "[3]\tvalid_0's ndcg@1: 0.588894\tvalid_0's ndcg@3: 0.682349\tvalid_0's ndcg@5: 0.838365\n",
            "[4]\tvalid_0's ndcg@1: 0.600624\tvalid_0's ndcg@3: 0.691592\tvalid_0's ndcg@5: 0.842959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 5/6 [33:26<06:39, 399.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.611376\tvalid_0's ndcg@3: 0.702598\tvalid_0's ndcg@5: 0.848127\n",
            "\n",
            "\n",
            "glove-twitter-100\n",
            "\n",
            "[1]\tvalid_0's ndcg@1: 0.473816\tvalid_0's ndcg@3: 0.585281\tvalid_0's ndcg@5: 0.79101\n",
            "[2]\tvalid_0's ndcg@1: 0.575574\tvalid_0's ndcg@3: 0.664197\tvalid_0's ndcg@5: 0.830895\n",
            "[3]\tvalid_0's ndcg@1: 0.596071\tvalid_0's ndcg@3: 0.687483\tvalid_0's ndcg@5: 0.841112\n",
            "[4]\tvalid_0's ndcg@1: 0.608723\tvalid_0's ndcg@3: 0.699835\tvalid_0's ndcg@5: 0.846792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [41:23<00:00, 413.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.614709\tvalid_0's ndcg@3: 0.707019\tvalid_0's ndcg@5: 0.849991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for embedding_name, vector_dim in tqdm(embeddings_list):\n",
        "\n",
        "    print()\n",
        "\n",
        "    current_embeddings = gensim.downloader.load(embedding_name)\n",
        "    current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "    print()\n",
        "    print(embedding_name)\n",
        "    print()\n",
        "\n",
        "    # Создаем эмбеддинги для датасета\n",
        "    train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train_raw]\n",
        "    val_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_val_raw]\n",
        "\n",
        "    # Подготавливаем данные для подачи в модель\n",
        "    X_train, qids_train = transform_data(train_emb, y_train, vector_dim)\n",
        "    X_val, qids_val = transform_data(val_emb, y_val, vector_dim)\n",
        "\n",
        "    # Создаем модель\n",
        "    ranker = lightgbm.LGBMRanker(\n",
        "        objective='lambdarank',\n",
        "        boosting_type='gbdt',\n",
        "        n_estimators=5,\n",
        "        importance_type='gain',\n",
        "        metric='ndcg',\n",
        "        num_leaves=10,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=-1,\n",
        "        label_gain=[i for i in range(5)]\n",
        "    )\n",
        "\n",
        "    # Обучаем модель\n",
        "    ranker.fit(\n",
        "        X=X_train,\n",
        "        y=y_train,\n",
        "        group=qids_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_group=[qids_val],\n",
        "        eval_at=[1, 3, 5]\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbjc_lRYuUrZ"
      },
      "source": [
        "## ('glove-wiki-gigaword-50', 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "3nkhl3LduDbM",
        "outputId": "ecc56963-0191-4514-e6f0-24d2b96fb6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.453291\tvalid_0's ndcg@3: 0.576642\tvalid_0's ndcg@5: 0.784891\n",
            "[2]\tvalid_0's ndcg@1: 0.556738\tvalid_0's ndcg@3: 0.656875\tvalid_0's ndcg@5: 0.825513\n",
            "[3]\tvalid_0's ndcg@1: 0.58817\tvalid_0's ndcg@3: 0.680489\tvalid_0's ndcg@5: 0.83778\n",
            "[4]\tvalid_0's ndcg@1: 0.601589\tvalid_0's ndcg@3: 0.694311\tvalid_0's ndcg@5: 0.843943\n",
            "[5]\tvalid_0's ndcg@1: 0.609617\tvalid_0's ndcg@3: 0.700847\tvalid_0's ndcg@5: 0.847255\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMRanker(importance_type='gain', label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric='ndcg', n_estimators=5, num_leaves=10,\n",
              "           objective='lambdarank')"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_name = embeddings_list[0][0]\n",
        "vector_dim = embeddings_list[0][1]\n",
        "\n",
        "current_embeddings = gensim.downloader.load(embedding_name)\n",
        "current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "# Создаем эмбеддинги для датасета\n",
        "train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train]\n",
        "val_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_val]\n",
        "\n",
        "# Подготавливаем данные для подачи в модель\n",
        "X_train, qids_train = transform_data(train_emb, y_train, vector_dim)\n",
        "X_val, qids_val = transform_data(val_emb, y_val, vector_dim)\n",
        "\n",
        "# Создаем модель\n",
        "ranker = lightgbm.LGBMRanker(\n",
        "    objective='lambdarank',\n",
        "    boosting_type='gbdt',\n",
        "    n_estimators=5,\n",
        "    importance_type='gain',\n",
        "    metric='ndcg',\n",
        "    num_leaves=10,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    label_gain=[i for i in range(5)]\n",
        ")\n",
        "\n",
        "# Обучаем модель\n",
        "ranker.fit(\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    group=qids_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[qids_val],\n",
        "    eval_at=[1, 3, 5]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZBMW_7rucjX"
      },
      "source": [
        "## ('glove-wiki-gigaword-100', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "P46boD_GueUq",
        "outputId": "82fbebc0-3318-4d57-a0e8-efd3880a929f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.451844\tvalid_0's ndcg@3: 0.578905\tvalid_0's ndcg@5: 0.785632\n",
            "[2]\tvalid_0's ndcg@1: 0.564936\tvalid_0's ndcg@3: 0.665218\tvalid_0's ndcg@5: 0.82949\n",
            "[3]\tvalid_0's ndcg@1: 0.597943\tvalid_0's ndcg@3: 0.690997\tvalid_0's ndcg@5: 0.842469\n",
            "[4]\tvalid_0's ndcg@1: 0.608823\tvalid_0's ndcg@3: 0.700837\tvalid_0's ndcg@5: 0.847122\n",
            "[5]\tvalid_0's ndcg@1: 0.617149\tvalid_0's ndcg@3: 0.707373\tvalid_0's ndcg@5: 0.850276\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMRanker(importance_type='gain', label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric='ndcg', n_estimators=5, num_leaves=10,\n",
              "           objective='lambdarank')"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_name = embeddings_list[1][0]\n",
        "vector_dim = embeddings_list[1][1]\n",
        "\n",
        "current_embeddings = gensim.downloader.load(embedding_name)\n",
        "current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "# Создаем эмбеддинги для датасета\n",
        "train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train_raw]\n",
        "val_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_val_raw]\n",
        "\n",
        "# Подготавливаем данные для подачи в модель\n",
        "X_train, qids_train = transform_data(train_emb, y_train, vector_dim)\n",
        "X_val, qids_val = transform_data(val_emb, y_val, vector_dim)\n",
        "\n",
        "# Создаем модель\n",
        "ranker = lightgbm.LGBMRanker(\n",
        "    objective='lambdarank',\n",
        "    boosting_type='gbdt',\n",
        "    n_estimators=5,\n",
        "    importance_type='gain',\n",
        "    metric='ndcg',\n",
        "    num_leaves=10,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    label_gain=[i for i in range(5)]\n",
        ")\n",
        "\n",
        "# Обучаем модель\n",
        "ranker.fit(\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    group=qids_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[qids_val],\n",
        "    eval_at=[1, 3, 5]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YigeshWNue04"
      },
      "source": [
        "## ('glove-wiki-gigaword-200', 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "keKe--jiug-4",
        "outputId": "edd17bf4-03c5-4fe0-f8c5-132da4e77996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.0% 249.5/252.1MB downloaded\n",
            "[1]\tvalid_0's ndcg@1: 0.450397\tvalid_0's ndcg@3: 0.583718\tvalid_0's ndcg@5: 0.786575\n",
            "[2]\tvalid_0's ndcg@1: 0.569362\tvalid_0's ndcg@3: 0.666479\tvalid_0's ndcg@5: 0.830534\n",
            "[3]\tvalid_0's ndcg@1: 0.60773\tvalid_0's ndcg@3: 0.694624\tvalid_0's ndcg@5: 0.844981\n",
            "[4]\tvalid_0's ndcg@1: 0.624128\tvalid_0's ndcg@3: 0.708904\tvalid_0's ndcg@5: 0.851969\n",
            "[5]\tvalid_0's ndcg@1: 0.627759\tvalid_0's ndcg@3: 0.714537\tvalid_0's ndcg@5: 0.854429\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMRanker(importance_type='gain', label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric='ndcg', n_estimators=5, num_leaves=10,\n",
              "           objective='lambdarank')"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_name = embeddings_list[2][0]\n",
        "vector_dim = embeddings_list[2][1]\n",
        "\n",
        "current_embeddings = gensim.downloader.load(embedding_name)\n",
        "current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "# Создаем эмбеддинги для датасета\n",
        "train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train_raw]\n",
        "val_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_val_raw]\n",
        "\n",
        "# Подготавливаем данные для подачи в модель\n",
        "X_train, qids_train = transform_data(train_emb, y_train, vector_dim)\n",
        "X_val, qids_val = transform_data(val_emb, y_val, vector_dim)\n",
        "\n",
        "# Создаем модель\n",
        "ranker = lightgbm.LGBMRanker(\n",
        "    objective='lambdarank',\n",
        "    boosting_type='gbdt',\n",
        "    n_estimators=5,\n",
        "    importance_type='gain',\n",
        "    metric='ndcg',\n",
        "    num_leaves=10,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    label_gain=[i for i in range(5)]\n",
        ")\n",
        "\n",
        "# Обучаем модель\n",
        "ranker.fit(\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    group=qids_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[qids_val],\n",
        "    eval_at=[1, 3, 5]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3HC6EYoYuhZ2"
      },
      "source": [
        "## ('glove-twitter-25', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "LE9OYKWyukcB",
        "outputId": "a5b284ab-ce34-4c8d-bf55-6fe6767cd3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
            "[1]\tvalid_0's ndcg@1: 0.459844\tvalid_0's ndcg@3: 0.568761\tvalid_0's ndcg@5: 0.78393\n",
            "[2]\tvalid_0's ndcg@1: 0.544638\tvalid_0's ndcg@3: 0.635997\tvalid_0's ndcg@5: 0.817476\n",
            "[3]\tvalid_0's ndcg@1: 0.566638\tvalid_0's ndcg@3: 0.666379\tvalid_0's ndcg@5: 0.830066\n",
            "[4]\tvalid_0's ndcg@1: 0.585589\tvalid_0's ndcg@3: 0.677775\tvalid_0's ndcg@5: 0.83635\n",
            "[5]\tvalid_0's ndcg@1: 0.59322\tvalid_0's ndcg@3: 0.685552\tvalid_0's ndcg@5: 0.839962\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMRanker(importance_type='gain', label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric='ndcg', n_estimators=5, num_leaves=10,\n",
              "           objective='lambdarank')"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_name = embeddings_list[3][0]\n",
        "vector_dim = embeddings_list[3][1]\n",
        "\n",
        "current_embeddings = gensim.downloader.load(embedding_name)\n",
        "current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "# Создаем эмбеддинги для датасета\n",
        "train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train_raw]\n",
        "val_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_val_raw]\n",
        "\n",
        "# Подготавливаем данные для подачи в модель\n",
        "X_train, qids_train = transform_data(train_emb, y_train, vector_dim)\n",
        "X_val, qids_val = transform_data(val_emb, y_val, vector_dim)\n",
        "\n",
        "# Создаем модель\n",
        "ranker = lightgbm.LGBMRanker(\n",
        "    objective='lambdarank',\n",
        "    boosting_type='gbdt',\n",
        "    n_estimators=5,\n",
        "    importance_type='gain',\n",
        "    metric='ndcg',\n",
        "    num_leaves=10,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    label_gain=[i for i in range(5)]\n",
        ")\n",
        "\n",
        "# Обучаем модель\n",
        "ranker.fit(\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    group=qids_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[qids_val],\n",
        "    eval_at=[1, 3, 5]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uubyHjjhuk_r"
      },
      "source": [
        "## ('glove-twitter-50', 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "xfgItz_oumzl",
        "outputId": "988eabc0-8ddc-4796-ea30-9c32c1795f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[================================================--] 97.1% 193.8/199.5MB downloaded[1]\tvalid_0's ndcg@1: 0.460823\tvalid_0's ndcg@3: 0.571338\tvalid_0's ndcg@5: 0.784834\n",
            "[2]\tvalid_0's ndcg@1: 0.564071\tvalid_0's ndcg@3: 0.656135\tvalid_0's ndcg@5: 0.826406\n",
            "[3]\tvalid_0's ndcg@1: 0.588894\tvalid_0's ndcg@3: 0.682349\tvalid_0's ndcg@5: 0.838365\n",
            "[4]\tvalid_0's ndcg@1: 0.600624\tvalid_0's ndcg@3: 0.691592\tvalid_0's ndcg@5: 0.842959\n",
            "[5]\tvalid_0's ndcg@1: 0.611376\tvalid_0's ndcg@3: 0.702598\tvalid_0's ndcg@5: 0.848127\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMRanker(importance_type='gain', label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric='ndcg', n_estimators=5, num_leaves=10,\n",
              "           objective='lambdarank')"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_name = embeddings_list[4][0]\n",
        "vector_dim = embeddings_list[4][1]\n",
        "\n",
        "current_embeddings = gensim.downloader.load(embedding_name)\n",
        "current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "# Создаем эмбеддинги для датасета\n",
        "train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train_raw]\n",
        "val_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_val_raw]\n",
        "\n",
        "# Подготавливаем данные для подачи в модель\n",
        "X_train, qids_train = transform_data(train_emb, y_train, vector_dim)\n",
        "X_val, qids_val = transform_data(val_emb, y_val, vector_dim)\n",
        "\n",
        "# Создаем модель\n",
        "ranker = lightgbm.LGBMRanker(\n",
        "    objective='lambdarank',\n",
        "    boosting_type='gbdt',\n",
        "    n_estimators=5,\n",
        "    importance_type='gain',\n",
        "    metric='ndcg',\n",
        "    num_leaves=10,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    label_gain=[i for i in range(5)]\n",
        ")\n",
        "\n",
        "# Обучаем модель\n",
        "ranker.fit(\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    group=qids_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[qids_val],\n",
        "    eval_at=[1, 3, 5]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGRKRm1unRV"
      },
      "source": [
        "## ('glove-twitter-100', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "g0bh_NvxuokA",
        "outputId": "867cc8cd-a4c2-4c1a-f0b4-0685b4600af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.9% 386.7/387.1MB downloaded\n",
            "[1]\tvalid_0's ndcg@1: 0.473816\tvalid_0's ndcg@3: 0.585281\tvalid_0's ndcg@5: 0.79101\n",
            "[2]\tvalid_0's ndcg@1: 0.575574\tvalid_0's ndcg@3: 0.664197\tvalid_0's ndcg@5: 0.830895\n",
            "[3]\tvalid_0's ndcg@1: 0.596071\tvalid_0's ndcg@3: 0.687483\tvalid_0's ndcg@5: 0.841112\n",
            "[4]\tvalid_0's ndcg@1: 0.608723\tvalid_0's ndcg@3: 0.699835\tvalid_0's ndcg@5: 0.846792\n",
            "[5]\tvalid_0's ndcg@1: 0.614709\tvalid_0's ndcg@3: 0.707019\tvalid_0's ndcg@5: 0.849991\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric=&#x27;ndcg&#x27;, n_estimators=5, num_leaves=10,\n",
              "           objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMRanker(importance_type='gain', label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.05, metric='ndcg', n_estimators=5, num_leaves=10,\n",
              "           objective='lambdarank')"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_name = embeddings_list[5][0]\n",
        "vector_dim = embeddings_list[5][1]\n",
        "\n",
        "current_embeddings = gensim.downloader.load(embedding_name)\n",
        "current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "# Создаем эмбеддинги для датасета\n",
        "train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train_raw]\n",
        "val_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_val_raw]\n",
        "\n",
        "# Подготавливаем данные для подачи в модель\n",
        "X_train, qids_train = transform_data(train_emb, y_train, vector_dim)\n",
        "X_val, qids_val = transform_data(val_emb, y_val, vector_dim)\n",
        "\n",
        "# Создаем модель\n",
        "ranker = lightgbm.LGBMRanker(\n",
        "    objective='lambdarank',\n",
        "    boosting_type='gbdt',\n",
        "    n_estimators=5,\n",
        "    importance_type='gain',\n",
        "    metric='ndcg',\n",
        "    num_leaves=10,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    label_gain=[i for i in range(5)]\n",
        ")\n",
        "\n",
        "# Обучаем модель\n",
        "ranker.fit(\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    group=qids_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_group=[qids_val],\n",
        "    eval_at=[1, 3, 5]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BihSXuGmG6sN"
      },
      "source": [
        "# Оптимизация гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD9SgAHcHNNe",
        "outputId": "48c58083-ca17-4aff-e041-182d6c131c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "vJ0h0Z89Hm3N"
      },
      "outputs": [],
      "source": [
        "embedding_name = embeddings_list[2][0]\n",
        "vector_dim = embeddings_list[2][1]\n",
        "\n",
        "current_embeddings = gensim.downloader.load(embedding_name)\n",
        "current_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "train_emb = [text_to_vec(row, current_embeddings, current_tokenizer, vector_dim) for row in X_train_raw]\n",
        "y = y_train\n",
        "\n",
        "idx = []\n",
        "for i in range(int(len(train_emb) / 5)):\n",
        "    idx.extend([i] * 5)\n",
        "\n",
        "embeddings_df = pd.DataFrame(train_emb, columns=[i for i in range(1, vector_dim+1)])\n",
        "embeddings_df['score'] = y\n",
        "embeddings_df['qid'] = idx\n",
        "\n",
        "qids = embeddings_df.groupby('qid')['qid'].count().to_numpy()\n",
        "X = embeddings_df.drop(['score'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moqBVlL-G95T",
        "outputId": "d990ab2e-89fa-42ac-8340-fa4b4a80b7a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:17:30,431] A new study created in memory with name: LGBMRanker\n",
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.520093\tvalid_0's ndcg@3: 0.616759\tvalid_0's ndcg@5: 0.807933\n",
            "[2]\tvalid_0's ndcg@1: 0.598549\tvalid_0's ndcg@3: 0.6816\tvalid_0's ndcg@5: 0.83981\n",
            "[3]\tvalid_0's ndcg@1: 0.617472\tvalid_0's ndcg@3: 0.703136\tvalid_0's ndcg@5: 0.849126\n",
            "[4]\tvalid_0's ndcg@1: 0.624672\tvalid_0's ndcg@3: 0.710577\tvalid_0's ndcg@5: 0.852701\n",
            "[5]\tvalid_0's ndcg@1: 0.62719\tvalid_0's ndcg@3: 0.714716\tvalid_0's ndcg@5: 0.854343\n",
            "[1]\tvalid_0's ndcg@1: 0.518869\tvalid_0's ndcg@3: 0.618025\tvalid_0's ndcg@5: 0.807903\n",
            "[2]\tvalid_0's ndcg@1: 0.596811\tvalid_0's ndcg@3: 0.684152\tvalid_0's ndcg@5: 0.840164\n",
            "[3]\tvalid_0's ndcg@1: 0.613712\tvalid_0's ndcg@3: 0.701198\tvalid_0's ndcg@5: 0.848045\n",
            "[4]\tvalid_0's ndcg@1: 0.620061\tvalid_0's ndcg@3: 0.707468\tvalid_0's ndcg@5: 0.85086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:18:11,789] Trial 0 finished with value: 0.8542439150390133 and parameters: {'num_leaves': 19, 'learning_rate': 0.03034246577425776, 'max_depth': 10}. Best is trial 0 with value: 0.8542439150390133.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.627421\tvalid_0's ndcg@3: 0.714053\tvalid_0's ndcg@5: 0.854145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.447826\tvalid_0's ndcg@3: 0.51194\tvalid_0's ndcg@5: 0.765343\n",
            "[2]\tvalid_0's ndcg@1: 0.554391\tvalid_0's ndcg@3: 0.607369\tvalid_0's ndcg@5: 0.810694\n",
            "[3]\tvalid_0's ndcg@1: 0.597875\tvalid_0's ndcg@3: 0.65409\tvalid_0's ndcg@5: 0.831376\n",
            "[4]\tvalid_0's ndcg@1: 0.615007\tvalid_0's ndcg@3: 0.678568\tvalid_0's ndcg@5: 0.841211\n",
            "[5]\tvalid_0's ndcg@1: 0.623023\tvalid_0's ndcg@3: 0.691242\tvalid_0's ndcg@5: 0.846167\n",
            "[1]\tvalid_0's ndcg@1: 0.446513\tvalid_0's ndcg@3: 0.507326\tvalid_0's ndcg@5: 0.763961\n",
            "[2]\tvalid_0's ndcg@1: 0.560172\tvalid_0's ndcg@3: 0.614078\tvalid_0's ndcg@5: 0.813644\n",
            "[3]\tvalid_0's ndcg@1: 0.59557\tvalid_0's ndcg@3: 0.654247\tvalid_0's ndcg@5: 0.83098\n",
            "[4]\tvalid_0's ndcg@1: 0.614705\tvalid_0's ndcg@3: 0.679849\tvalid_0's ndcg@5: 0.841771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:18:50,423] Trial 1 finished with value: 0.846717377128898 and parameters: {'num_leaves': 46, 'learning_rate': 0.09657154838619968, 'max_depth': 4}. Best is trial 0 with value: 0.8542439150390133.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.622207\tvalid_0's ndcg@3: 0.694397\tvalid_0's ndcg@5: 0.847267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.545027\tvalid_0's ndcg@3: 0.657042\tvalid_0's ndcg@5: 0.823795\n",
            "[2]\tvalid_0's ndcg@1: 0.593726\tvalid_0's ndcg@3: 0.695866\tvalid_0's ndcg@5: 0.843441\n",
            "[3]\tvalid_0's ndcg@1: 0.604987\tvalid_0's ndcg@3: 0.701077\tvalid_0's ndcg@5: 0.846968\n",
            "[4]\tvalid_0's ndcg@1: 0.612648\tvalid_0's ndcg@3: 0.708378\tvalid_0's ndcg@5: 0.85056\n",
            "[5]\tvalid_0's ndcg@1: 0.623466\tvalid_0's ndcg@3: 0.714662\tvalid_0's ndcg@5: 0.85416\n",
            "[1]\tvalid_0's ndcg@1: 0.54712\tvalid_0's ndcg@3: 0.661069\tvalid_0's ndcg@5: 0.825651\n",
            "[2]\tvalid_0's ndcg@1: 0.609066\tvalid_0's ndcg@3: 0.705583\tvalid_0's ndcg@5: 0.848742\n",
            "[3]\tvalid_0's ndcg@1: 0.617099\tvalid_0's ndcg@3: 0.710054\tvalid_0's ndcg@5: 0.851559\n",
            "[4]\tvalid_0's ndcg@1: 0.622083\tvalid_0's ndcg@3: 0.714476\tvalid_0's ndcg@5: 0.853642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:19:31,637] Trial 2 finished with value: 0.8550859070041954 and parameters: {'num_leaves': 47, 'learning_rate': 0.01457440403042895, 'max_depth': 0}. Best is trial 2 with value: 0.8550859070041954.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.628644\tvalid_0's ndcg@3: 0.718971\tvalid_0's ndcg@5: 0.856011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.183355\tvalid_0's ndcg@3: 0.332443\tvalid_0's ndcg@5: 0.668818\n",
            "[2]\tvalid_0's ndcg@1: 0.298858\tvalid_0's ndcg@3: 0.402918\tvalid_0's ndcg@5: 0.708597\n",
            "[3]\tvalid_0's ndcg@1: 0.357115\tvalid_0's ndcg@3: 0.441501\tvalid_0's ndcg@5: 0.72953\n",
            "[4]\tvalid_0's ndcg@1: 0.419859\tvalid_0's ndcg@3: 0.486014\tvalid_0's ndcg@5: 0.752905\n",
            "[5]\tvalid_0's ndcg@1: 0.464549\tvalid_0's ndcg@3: 0.522969\tvalid_0's ndcg@5: 0.771202\n",
            "[1]\tvalid_0's ndcg@1: 0.168529\tvalid_0's ndcg@3: 0.323784\tvalid_0's ndcg@5: 0.663856\n",
            "[2]\tvalid_0's ndcg@1: 0.288146\tvalid_0's ndcg@3: 0.395031\tvalid_0's ndcg@5: 0.704486\n",
            "[3]\tvalid_0's ndcg@1: 0.374104\tvalid_0's ndcg@3: 0.452523\tvalid_0's ndcg@5: 0.735611\n",
            "[4]\tvalid_0's ndcg@1: 0.425374\tvalid_0's ndcg@3: 0.492152\tvalid_0's ndcg@5: 0.755804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:20:09,155] Trial 3 finished with value: 0.7720850814216662 and parameters: {'num_leaves': 13, 'learning_rate': 0.03724940353011337, 'max_depth': 1}. Best is trial 2 with value: 0.8550859070041954.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.469355\tvalid_0's ndcg@3: 0.525789\tvalid_0's ndcg@5: 0.772968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.474321\tvalid_0's ndcg@3: 0.564136\tvalid_0's ndcg@5: 0.785106\n",
            "[2]\tvalid_0's ndcg@1: 0.574484\tvalid_0's ndcg@3: 0.648852\tvalid_0's ndcg@5: 0.826087\n",
            "[3]\tvalid_0's ndcg@1: 0.604685\tvalid_0's ndcg@3: 0.677165\tvalid_0's ndcg@5: 0.83936\n",
            "[4]\tvalid_0's ndcg@1: 0.609846\tvalid_0's ndcg@3: 0.686492\tvalid_0's ndcg@5: 0.842907\n",
            "[5]\tvalid_0's ndcg@1: 0.619316\tvalid_0's ndcg@3: 0.696583\tvalid_0's ndcg@5: 0.847328\n",
            "[1]\tvalid_0's ndcg@1: 0.469728\tvalid_0's ndcg@3: 0.549566\tvalid_0's ndcg@5: 0.780247\n",
            "[2]\tvalid_0's ndcg@1: 0.568525\tvalid_0's ndcg@3: 0.635248\tvalid_0's ndcg@5: 0.821223\n",
            "[3]\tvalid_0's ndcg@1: 0.596599\tvalid_0's ndcg@3: 0.668972\tvalid_0's ndcg@5: 0.835549\n",
            "[4]\tvalid_0's ndcg@1: 0.608019\tvalid_0's ndcg@3: 0.680269\tvalid_0's ndcg@5: 0.840923\n",
            "[5]\tvalid_0's ndcg@1: 0.619192\tvalid_0's ndcg@3: 0.692786\tvalid_0's ndcg@5: 0.846239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:20:49,449] Trial 4 finished with value: 0.8467836554684394 and parameters: {'num_leaves': 10, 'learning_rate': 0.02623553883463248, 'max_depth': 6}. Best is trial 2 with value: 0.8550859070041954.\n",
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.535752\tvalid_0's ndcg@3: 0.598751\tvalid_0's ndcg@5: 0.805249\n",
            "[2]\tvalid_0's ndcg@1: 0.596953\tvalid_0's ndcg@3: 0.664782\tvalid_0's ndcg@5: 0.834467\n",
            "[3]\tvalid_0's ndcg@1: 0.607895\tvalid_0's ndcg@3: 0.67887\tvalid_0's ndcg@5: 0.84045\n",
            "[4]\tvalid_0's ndcg@1: 0.615876\tvalid_0's ndcg@3: 0.68745\tvalid_0's ndcg@5: 0.844423\n",
            "[5]\tvalid_0's ndcg@1: 0.622952\tvalid_0's ndcg@3: 0.698088\tvalid_0's ndcg@5: 0.848799\n",
            "[1]\tvalid_0's ndcg@1: 0.536479\tvalid_0's ndcg@3: 0.598632\tvalid_0's ndcg@5: 0.805282\n",
            "[2]\tvalid_0's ndcg@1: 0.599596\tvalid_0's ndcg@3: 0.67126\tvalid_0's ndcg@5: 0.836579\n",
            "[3]\tvalid_0's ndcg@1: 0.616674\tvalid_0's ndcg@3: 0.688236\tvalid_0's ndcg@5: 0.844382\n",
            "[4]\tvalid_0's ndcg@1: 0.618146\tvalid_0's ndcg@3: 0.691611\tvalid_0's ndcg@5: 0.845682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:21:29,856] Trial 5 finished with value: 0.8484166557946584 and parameters: {'num_leaves': 40, 'learning_rate': 0.015758984380006363, 'max_depth': 7}. Best is trial 2 with value: 0.8550859070041954.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.624299\tvalid_0's ndcg@3: 0.696535\tvalid_0's ndcg@5: 0.848035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.50665\tvalid_0's ndcg@3: 0.588437\tvalid_0's ndcg@5: 0.797541\n",
            "[2]\tvalid_0's ndcg@1: 0.591278\tvalid_0's ndcg@3: 0.668405\tvalid_0's ndcg@5: 0.834538\n",
            "[3]\tvalid_0's ndcg@1: 0.613712\tvalid_0's ndcg@3: 0.686206\tvalid_0's ndcg@5: 0.843338\n",
            "[4]\tvalid_0's ndcg@1: 0.617259\tvalid_0's ndcg@3: 0.694207\tvalid_0's ndcg@5: 0.846415\n",
            "[5]\tvalid_0's ndcg@1: 0.619813\tvalid_0's ndcg@3: 0.698406\tvalid_0's ndcg@5: 0.848152\n",
            "[1]\tvalid_0's ndcg@1: 0.503494\tvalid_0's ndcg@3: 0.585015\tvalid_0's ndcg@5: 0.795878\n",
            "[2]\tvalid_0's ndcg@1: 0.586809\tvalid_0's ndcg@3: 0.664236\tvalid_0's ndcg@5: 0.832392\n",
            "[3]\tvalid_0's ndcg@1: 0.610467\tvalid_0's ndcg@3: 0.685238\tvalid_0's ndcg@5: 0.842372\n",
            "[4]\tvalid_0's ndcg@1: 0.618323\tvalid_0's ndcg@3: 0.697392\tvalid_0's ndcg@5: 0.84725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:22:12,367] Trial 6 finished with value: 0.8486367497335572 and parameters: {'num_leaves': 16, 'learning_rate': 0.022656452451195342, 'max_depth': 7}. Best is trial 2 with value: 0.8550859070041954.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.621302\tvalid_0's ndcg@3: 0.701329\tvalid_0's ndcg@5: 0.849122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.439881\tvalid_0's ndcg@3: 0.509472\tvalid_0's ndcg@5: 0.763413\n",
            "[2]\tvalid_0's ndcg@1: 0.547049\tvalid_0's ndcg@3: 0.601774\tvalid_0's ndcg@5: 0.807818\n",
            "[3]\tvalid_0's ndcg@1: 0.572728\tvalid_0's ndcg@3: 0.62842\tvalid_0's ndcg@5: 0.819806\n",
            "[4]\tvalid_0's ndcg@1: 0.594116\tvalid_0's ndcg@3: 0.65222\tvalid_0's ndcg@5: 0.830177\n",
            "[5]\tvalid_0's ndcg@1: 0.601387\tvalid_0's ndcg@3: 0.663031\tvalid_0's ndcg@5: 0.834564\n",
            "[1]\tvalid_0's ndcg@1: 0.434206\tvalid_0's ndcg@3: 0.503285\tvalid_0's ndcg@5: 0.760829\n",
            "[2]\tvalid_0's ndcg@1: 0.548273\tvalid_0's ndcg@3: 0.606249\tvalid_0's ndcg@5: 0.80965\n",
            "[3]\tvalid_0's ndcg@1: 0.576045\tvalid_0's ndcg@3: 0.632919\tvalid_0's ndcg@5: 0.821844\n",
            "[4]\tvalid_0's ndcg@1: 0.587909\tvalid_0's ndcg@3: 0.642157\tvalid_0's ndcg@5: 0.826431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:22:50,290] Trial 7 finished with value: 0.8312619170291282 and parameters: {'num_leaves': 10, 'learning_rate': 0.015205702259855751, 'max_depth': 4}. Best is trial 2 with value: 0.8550859070041954.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.59009\tvalid_0's ndcg@3: 0.646002\tvalid_0's ndcg@5: 0.82796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.517415\tvalid_0's ndcg@3: 0.615777\tvalid_0's ndcg@5: 0.807226\n",
            "[2]\tvalid_0's ndcg@1: 0.598815\tvalid_0's ndcg@3: 0.684776\tvalid_0's ndcg@5: 0.840784\n",
            "[3]\tvalid_0's ndcg@1: 0.61944\tvalid_0's ndcg@3: 0.703905\tvalid_0's ndcg@5: 0.849811\n",
            "[4]\tvalid_0's ndcg@1: 0.626339\tvalid_0's ndcg@3: 0.712623\tvalid_0's ndcg@5: 0.853647\n",
            "[5]\tvalid_0's ndcg@1: 0.632174\tvalid_0's ndcg@3: 0.716957\tvalid_0's ndcg@5: 0.855944\n",
            "[1]\tvalid_0's ndcg@1: 0.517397\tvalid_0's ndcg@3: 0.617507\tvalid_0's ndcg@5: 0.807507\n",
            "[2]\tvalid_0's ndcg@1: 0.597308\tvalid_0's ndcg@3: 0.68302\tvalid_0's ndcg@5: 0.840059\n",
            "[3]\tvalid_0's ndcg@1: 0.620416\tvalid_0's ndcg@3: 0.705558\tvalid_0's ndcg@5: 0.850419\n",
            "[4]\tvalid_0's ndcg@1: 0.629584\tvalid_0's ndcg@3: 0.71386\tvalid_0's ndcg@5: 0.854197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:23:31,945] Trial 8 finished with value: 0.8561561597196949 and parameters: {'num_leaves': 18, 'learning_rate': 0.051866749766626676, 'max_depth': 10}. Best is trial 8 with value: 0.8561561597196949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.63345\tvalid_0's ndcg@3: 0.718601\tvalid_0's ndcg@5: 0.856369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.387831\tvalid_0's ndcg@3: 0.464819\tvalid_0's ndcg@5: 0.741628\n",
            "[2]\tvalid_0's ndcg@1: 0.504327\tvalid_0's ndcg@3: 0.556357\tvalid_0's ndcg@5: 0.787558\n",
            "[3]\tvalid_0's ndcg@1: 0.563666\tvalid_0's ndcg@3: 0.616228\tvalid_0's ndcg@5: 0.814949\n",
            "[4]\tvalid_0's ndcg@1: 0.592732\tvalid_0's ndcg@3: 0.648072\tvalid_0's ndcg@5: 0.829019\n",
            "[5]\tvalid_0's ndcg@1: 0.603284\tvalid_0's ndcg@3: 0.665041\tvalid_0's ndcg@5: 0.83574\n",
            "[1]\tvalid_0's ndcg@1: 0.382262\tvalid_0's ndcg@3: 0.458253\tvalid_0's ndcg@5: 0.73879\n",
            "[2]\tvalid_0's ndcg@1: 0.506544\tvalid_0's ndcg@3: 0.556401\tvalid_0's ndcg@5: 0.788005\n",
            "[3]\tvalid_0's ndcg@1: 0.559569\tvalid_0's ndcg@3: 0.610674\tvalid_0's ndcg@5: 0.812563\n",
            "[4]\tvalid_0's ndcg@1: 0.584362\tvalid_0's ndcg@3: 0.637585\tvalid_0's ndcg@5: 0.824482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:24:10,045] Trial 9 finished with value: 0.8349913323984774 and parameters: {'num_leaves': 18, 'learning_rate': 0.045102997953383996, 'max_depth': 3}. Best is trial 8 with value: 0.8561561597196949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.60238\tvalid_0's ndcg@3: 0.66098\tvalid_0's ndcg@5: 0.834243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.531957\tvalid_0's ndcg@3: 0.622985\tvalid_0's ndcg@5: 0.811451\n",
            "[2]\tvalid_0's ndcg@1: 0.603213\tvalid_0's ndcg@3: 0.686482\tvalid_0's ndcg@5: 0.841882\n",
            "[3]\tvalid_0's ndcg@1: 0.622296\tvalid_0's ndcg@3: 0.706538\tvalid_0's ndcg@5: 0.850975\n",
            "[4]\tvalid_0's ndcg@1: 0.627917\tvalid_0's ndcg@3: 0.713243\tvalid_0's ndcg@5: 0.854104\n",
            "[5]\tvalid_0's ndcg@1: 0.631145\tvalid_0's ndcg@3: 0.71921\tvalid_0's ndcg@5: 0.856278\n",
            "[1]\tvalid_0's ndcg@1: 0.532826\tvalid_0's ndcg@3: 0.625505\tvalid_0's ndcg@5: 0.812572\n",
            "[2]\tvalid_0's ndcg@1: 0.603178\tvalid_0's ndcg@3: 0.686615\tvalid_0's ndcg@5: 0.842153\n",
            "[3]\tvalid_0's ndcg@1: 0.624672\tvalid_0's ndcg@3: 0.707362\tvalid_0's ndcg@5: 0.85161\n",
            "[4]\tvalid_0's ndcg@1: 0.631358\tvalid_0's ndcg@3: 0.71575\tvalid_0's ndcg@5: 0.85542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:24:50,441] Trial 10 finished with value: 0.8571229675665468 and parameters: {'num_leaves': 31, 'learning_rate': 0.05711752473804054, 'max_depth': 10}. Best is trial 10 with value: 0.8571229675665468.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.637813\tvalid_0's ndcg@3: 0.721036\tvalid_0's ndcg@5: 0.857968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.531957\tvalid_0's ndcg@3: 0.622985\tvalid_0's ndcg@5: 0.811451\n",
            "[2]\tvalid_0's ndcg@1: 0.606122\tvalid_0's ndcg@3: 0.687055\tvalid_0's ndcg@5: 0.842653\n",
            "[3]\tvalid_0's ndcg@1: 0.621107\tvalid_0's ndcg@3: 0.707874\tvalid_0's ndcg@5: 0.851254\n",
            "[4]\tvalid_0's ndcg@1: 0.628893\tvalid_0's ndcg@3: 0.715112\tvalid_0's ndcg@5: 0.85466\n",
            "[5]\tvalid_0's ndcg@1: 0.633965\tvalid_0's ndcg@3: 0.719378\tvalid_0's ndcg@5: 0.856911\n",
            "[1]\tvalid_0's ndcg@1: 0.532826\tvalid_0's ndcg@3: 0.625505\tvalid_0's ndcg@5: 0.812572\n",
            "[2]\tvalid_0's ndcg@1: 0.603302\tvalid_0's ndcg@3: 0.686525\tvalid_0's ndcg@5: 0.842142\n",
            "[3]\tvalid_0's ndcg@1: 0.623767\tvalid_0's ndcg@3: 0.707025\tvalid_0's ndcg@5: 0.851382\n",
            "[4]\tvalid_0's ndcg@1: 0.63017\tvalid_0's ndcg@3: 0.714397\tvalid_0's ndcg@5: 0.854893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:25:31,211] Trial 11 finished with value: 0.8571688150303499 and parameters: {'num_leaves': 31, 'learning_rate': 0.0561565680701163, 'max_depth': 10}. Best is trial 11 with value: 0.8571688150303499.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.635578\tvalid_0's ndcg@3: 0.720028\tvalid_0's ndcg@5: 0.857427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.531602\tvalid_0's ndcg@3: 0.617107\tvalid_0's ndcg@5: 0.809807\n",
            "[2]\tvalid_0's ndcg@1: 0.604331\tvalid_0's ndcg@3: 0.682323\tvalid_0's ndcg@5: 0.840726\n",
            "[3]\tvalid_0's ndcg@1: 0.623165\tvalid_0's ndcg@3: 0.703961\tvalid_0's ndcg@5: 0.850292\n",
            "[4]\tvalid_0's ndcg@1: 0.631375\tvalid_0's ndcg@3: 0.712502\tvalid_0's ndcg@5: 0.854477\n",
            "[5]\tvalid_0's ndcg@1: 0.635312\tvalid_0's ndcg@3: 0.716961\tvalid_0's ndcg@5: 0.856493\n",
            "[1]\tvalid_0's ndcg@1: 0.532613\tvalid_0's ndcg@3: 0.619759\tvalid_0's ndcg@5: 0.810747\n",
            "[2]\tvalid_0's ndcg@1: 0.602983\tvalid_0's ndcg@3: 0.684279\tvalid_0's ndcg@5: 0.841418\n",
            "[3]\tvalid_0's ndcg@1: 0.620948\tvalid_0's ndcg@3: 0.704142\tvalid_0's ndcg@5: 0.850115\n",
            "[4]\tvalid_0's ndcg@1: 0.628343\tvalid_0's ndcg@3: 0.714415\tvalid_0's ndcg@5: 0.854359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:26:13,503] Trial 12 finished with value: 0.856941606332575 and parameters: {'num_leaves': 32, 'learning_rate': 0.06394419458376197, 'max_depth': 9}. Best is trial 11 with value: 0.8571688150303499.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.635986\tvalid_0's ndcg@3: 0.719813\tvalid_0's ndcg@5: 0.85739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.525325\tvalid_0's ndcg@3: 0.607163\tvalid_0's ndcg@5: 0.805969\n",
            "[2]\tvalid_0's ndcg@1: 0.601174\tvalid_0's ndcg@3: 0.680068\tvalid_0's ndcg@5: 0.839821\n",
            "[3]\tvalid_0's ndcg@1: 0.622207\tvalid_0's ndcg@3: 0.702312\tvalid_0's ndcg@5: 0.849661\n",
            "[4]\tvalid_0's ndcg@1: 0.630932\tvalid_0's ndcg@3: 0.711192\tvalid_0's ndcg@5: 0.853622\n",
            "[5]\tvalid_0's ndcg@1: 0.637476\tvalid_0's ndcg@3: 0.717575\tvalid_0's ndcg@5: 0.85666\n",
            "[1]\tvalid_0's ndcg@1: 0.528073\tvalid_0's ndcg@3: 0.607016\tvalid_0's ndcg@5: 0.806306\n",
            "[2]\tvalid_0's ndcg@1: 0.601848\tvalid_0's ndcg@3: 0.677167\tvalid_0's ndcg@5: 0.838838\n",
            "[3]\tvalid_0's ndcg@1: 0.618891\tvalid_0's ndcg@3: 0.698745\tvalid_0's ndcg@5: 0.848069\n",
            "[4]\tvalid_0's ndcg@1: 0.628875\tvalid_0's ndcg@3: 0.710233\tvalid_0's ndcg@5: 0.853376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:26:55,145] Trial 13 finished with value: 0.8562103360207252 and parameters: {'num_leaves': 29, 'learning_rate': 0.06924883451258783, 'max_depth': 8}. Best is trial 11 with value: 0.8571688150303499.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.632901\tvalid_0's ndcg@3: 0.716352\tvalid_0's ndcg@5: 0.855761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.53898\tvalid_0's ndcg@3: 0.62524\tvalid_0's ndcg@5: 0.813306\n",
            "[2]\tvalid_0's ndcg@1: 0.605625\tvalid_0's ndcg@3: 0.689608\tvalid_0's ndcg@5: 0.84305\n",
            "[3]\tvalid_0's ndcg@1: 0.622828\tvalid_0's ndcg@3: 0.708451\tvalid_0's ndcg@5: 0.851441\n",
            "[4]\tvalid_0's ndcg@1: 0.630932\tvalid_0's ndcg@3: 0.71635\tvalid_0's ndcg@5: 0.855348\n",
            "[5]\tvalid_0's ndcg@1: 0.6315\tvalid_0's ndcg@3: 0.718325\tvalid_0's ndcg@5: 0.856126\n",
            "[1]\tvalid_0's ndcg@1: 0.53937\tvalid_0's ndcg@3: 0.628567\tvalid_0's ndcg@5: 0.814585\n",
            "[2]\tvalid_0's ndcg@1: 0.604721\tvalid_0's ndcg@3: 0.691184\tvalid_0's ndcg@5: 0.843529\n",
            "[3]\tvalid_0's ndcg@1: 0.619884\tvalid_0's ndcg@3: 0.707149\tvalid_0's ndcg@5: 0.850648\n",
            "[4]\tvalid_0's ndcg@1: 0.626782\tvalid_0's ndcg@3: 0.714196\tvalid_0's ndcg@5: 0.854012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:27:35,649] Trial 14 finished with value: 0.8565694085852884 and parameters: {'num_leaves': 36, 'learning_rate': 0.041128066787510846, 'max_depth': 10}. Best is trial 11 with value: 0.8571688150303499.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.634479\tvalid_0's ndcg@3: 0.719629\tvalid_0's ndcg@5: 0.857013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.51057\tvalid_0's ndcg@3: 0.578348\tvalid_0's ndcg@5: 0.795128\n",
            "[2]\tvalid_0's ndcg@1: 0.593584\tvalid_0's ndcg@3: 0.657841\tvalid_0's ndcg@5: 0.831876\n",
            "[3]\tvalid_0's ndcg@1: 0.6149\tvalid_0's ndcg@3: 0.686287\tvalid_0's ndcg@5: 0.843793\n",
            "[4]\tvalid_0's ndcg@1: 0.625115\tvalid_0's ndcg@3: 0.700315\tvalid_0's ndcg@5: 0.849389\n",
            "[5]\tvalid_0's ndcg@1: 0.628786\tvalid_0's ndcg@3: 0.706064\tvalid_0's ndcg@5: 0.851963\n",
            "[1]\tvalid_0's ndcg@1: 0.498794\tvalid_0's ndcg@3: 0.5617\tvalid_0's ndcg@5: 0.788396\n",
            "[2]\tvalid_0's ndcg@1: 0.592715\tvalid_0's ndcg@3: 0.656359\tvalid_0's ndcg@5: 0.831155\n",
            "[3]\tvalid_0's ndcg@1: 0.618288\tvalid_0's ndcg@3: 0.690571\tvalid_0's ndcg@5: 0.84555\n",
            "[4]\tvalid_0's ndcg@1: 0.627084\tvalid_0's ndcg@3: 0.704823\tvalid_0's ndcg@5: 0.851217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:28:16,772] Trial 15 finished with value: 0.8527548701747297 and parameters: {'num_leaves': 25, 'learning_rate': 0.05903178864813362, 'max_depth': 6}. Best is trial 11 with value: 0.8571688150303499.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.631145\tvalid_0's ndcg@3: 0.710762\tvalid_0's ndcg@5: 0.853547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.183355\tvalid_0's ndcg@3: 0.332443\tvalid_0's ndcg@5: 0.668818\n",
            "[2]\tvalid_0's ndcg@1: 0.298858\tvalid_0's ndcg@3: 0.402918\tvalid_0's ndcg@5: 0.708597\n",
            "[3]\tvalid_0's ndcg@1: 0.371036\tvalid_0's ndcg@3: 0.455565\tvalid_0's ndcg@5: 0.736114\n",
            "[4]\tvalid_0's ndcg@1: 0.424328\tvalid_0's ndcg@3: 0.493271\tvalid_0's ndcg@5: 0.755851\n",
            "[5]\tvalid_0's ndcg@1: 0.464673\tvalid_0's ndcg@3: 0.524984\tvalid_0's ndcg@5: 0.771806\n",
            "[1]\tvalid_0's ndcg@1: 0.168529\tvalid_0's ndcg@3: 0.323784\tvalid_0's ndcg@5: 0.663856\n",
            "[2]\tvalid_0's ndcg@1: 0.288146\tvalid_0's ndcg@3: 0.395031\tvalid_0's ndcg@5: 0.704486\n",
            "[3]\tvalid_0's ndcg@1: 0.374104\tvalid_0's ndcg@3: 0.452523\tvalid_0's ndcg@5: 0.735611\n",
            "[4]\tvalid_0's ndcg@1: 0.4283\tvalid_0's ndcg@3: 0.494601\tvalid_0's ndcg@5: 0.757004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:28:55,889] Trial 16 finished with value: 0.7738788818796662 and parameters: {'num_leaves': 2, 'learning_rate': 0.0808039511238296, 'max_depth': 9}. Best is trial 11 with value: 0.8571688150303499.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.47542\tvalid_0's ndcg@3: 0.532947\tvalid_0's ndcg@5: 0.775952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.305597\tvalid_0's ndcg@3: 0.405798\tvalid_0's ndcg@5: 0.710563\n",
            "[2]\tvalid_0's ndcg@1: 0.41977\tvalid_0's ndcg@3: 0.484742\tvalid_0's ndcg@5: 0.752728\n",
            "[3]\tvalid_0's ndcg@1: 0.489413\tvalid_0's ndcg@3: 0.539248\tvalid_0's ndcg@5: 0.779997\n",
            "[4]\tvalid_0's ndcg@1: 0.533642\tvalid_0's ndcg@3: 0.576345\tvalid_0's ndcg@5: 0.798294\n",
            "[5]\tvalid_0's ndcg@1: 0.562141\tvalid_0's ndcg@3: 0.609367\tvalid_0's ndcg@5: 0.812544\n",
            "[1]\tvalid_0's ndcg@1: 0.284192\tvalid_0's ndcg@3: 0.391073\tvalid_0's ndcg@5: 0.702772\n",
            "[2]\tvalid_0's ndcg@1: 0.430056\tvalid_0's ndcg@3: 0.495034\tvalid_0's ndcg@5: 0.757429\n",
            "[3]\tvalid_0's ndcg@1: 0.505125\tvalid_0's ndcg@3: 0.554439\tvalid_0's ndcg@5: 0.787179\n",
            "[4]\tvalid_0's ndcg@1: 0.548237\tvalid_0's ndcg@3: 0.594989\tvalid_0's ndcg@5: 0.806063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:29:33,819] Trial 17 finished with value: 0.8157365717948482 and parameters: {'num_leaves': 24, 'learning_rate': 0.053728788554106593, 'max_depth': 2}. Best is trial 11 with value: 0.8571688150303499.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.573615\tvalid_0's ndcg@3: 0.62433\tvalid_0's ndcg@5: 0.818929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.535344\tvalid_0's ndcg@3: 0.611167\tvalid_0's ndcg@5: 0.808864\n",
            "[2]\tvalid_0's ndcg@1: 0.603231\tvalid_0's ndcg@3: 0.682715\tvalid_0's ndcg@5: 0.840933\n",
            "[3]\tvalid_0's ndcg@1: 0.62093\tvalid_0's ndcg@3: 0.704712\tvalid_0's ndcg@5: 0.850148\n",
            "[4]\tvalid_0's ndcg@1: 0.630436\tvalid_0's ndcg@3: 0.714176\tvalid_0's ndcg@5: 0.854548\n",
            "[5]\tvalid_0's ndcg@1: 0.636536\tvalid_0's ndcg@3: 0.719213\tvalid_0's ndcg@5: 0.857123\n",
            "[1]\tvalid_0's ndcg@1: 0.539831\tvalid_0's ndcg@3: 0.611237\tvalid_0's ndcg@5: 0.809604\n",
            "[2]\tvalid_0's ndcg@1: 0.605217\tvalid_0's ndcg@3: 0.682407\tvalid_0's ndcg@5: 0.840799\n",
            "[3]\tvalid_0's ndcg@1: 0.625186\tvalid_0's ndcg@3: 0.704691\tvalid_0's ndcg@5: 0.850849\n",
            "[4]\tvalid_0's ndcg@1: 0.636323\tvalid_0's ndcg@3: 0.715424\tvalid_0's ndcg@5: 0.855903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:30:14,375] Trial 18 finished with value: 0.8573924765453034 and parameters: {'num_leaves': 40, 'learning_rate': 0.09848825590650033, 'max_depth': 8}. Best is trial 18 with value: 0.8573924765453034.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.638842\tvalid_0's ndcg@3: 0.72008\tvalid_0's ndcg@5: 0.857662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.535149\tvalid_0's ndcg@3: 0.61091\tvalid_0's ndcg@5: 0.808768\n",
            "[2]\tvalid_0's ndcg@1: 0.603834\tvalid_0's ndcg@3: 0.680256\tvalid_0's ndcg@5: 0.840157\n",
            "[3]\tvalid_0's ndcg@1: 0.622118\tvalid_0's ndcg@3: 0.704077\tvalid_0's ndcg@5: 0.850338\n",
            "[4]\tvalid_0's ndcg@1: 0.629567\tvalid_0's ndcg@3: 0.712855\tvalid_0's ndcg@5: 0.854307\n",
            "[5]\tvalid_0's ndcg@1: 0.631535\tvalid_0's ndcg@3: 0.717476\tvalid_0's ndcg@5: 0.85607\n",
            "[1]\tvalid_0's ndcg@1: 0.538909\tvalid_0's ndcg@3: 0.610819\tvalid_0's ndcg@5: 0.809284\n",
            "[2]\tvalid_0's ndcg@1: 0.603302\tvalid_0's ndcg@3: 0.681461\tvalid_0's ndcg@5: 0.840166\n",
            "[3]\tvalid_0's ndcg@1: 0.622154\tvalid_0's ndcg@3: 0.703711\tvalid_0's ndcg@5: 0.850212\n",
            "[4]\tvalid_0's ndcg@1: 0.632706\tvalid_0's ndcg@3: 0.715516\tvalid_0's ndcg@5: 0.855273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:30:56,023] Trial 19 finished with value: 0.8572864531359073 and parameters: {'num_leaves': 39, 'learning_rate': 0.09973185872073859, 'max_depth': 8}. Best is trial 18 with value: 0.8573924765453034.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.640792\tvalid_0's ndcg@3: 0.721841\tvalid_0's ndcg@5: 0.858503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.489962\tvalid_0's ndcg@3: 0.55119\tvalid_0's ndcg@5: 0.783795\n",
            "[2]\tvalid_0's ndcg@1: 0.581294\tvalid_0's ndcg@3: 0.638858\tvalid_0's ndcg@5: 0.824253\n",
            "[3]\tvalid_0's ndcg@1: 0.610343\tvalid_0's ndcg@3: 0.675164\tvalid_0's ndcg@5: 0.83956\n",
            "[4]\tvalid_0's ndcg@1: 0.618855\tvalid_0's ndcg@3: 0.692297\tvalid_0's ndcg@5: 0.846206\n",
            "[5]\tvalid_0's ndcg@1: 0.62563\tvalid_0's ndcg@3: 0.703129\tvalid_0's ndcg@5: 0.8505\n",
            "[1]\tvalid_0's ndcg@1: 0.487178\tvalid_0's ndcg@3: 0.541958\tvalid_0's ndcg@5: 0.780691\n",
            "[2]\tvalid_0's ndcg@1: 0.580975\tvalid_0's ndcg@3: 0.634931\tvalid_0's ndcg@5: 0.823016\n",
            "[3]\tvalid_0's ndcg@1: 0.607629\tvalid_0's ndcg@3: 0.674993\tvalid_0's ndcg@5: 0.839185\n",
            "[4]\tvalid_0's ndcg@1: 0.618979\tvalid_0's ndcg@3: 0.692455\tvalid_0's ndcg@5: 0.846149\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:31:36,948] Trial 20 finished with value: 0.8506957127824614 and parameters: {'num_leaves': 40, 'learning_rate': 0.09810317819286578, 'max_depth': 5}. Best is trial 18 with value: 0.8573924765453034.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.627314\tvalid_0's ndcg@3: 0.703746\tvalid_0's ndcg@5: 0.850891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.537402\tvalid_0's ndcg@3: 0.611804\tvalid_0's ndcg@5: 0.809357\n",
            "[2]\tvalid_0's ndcg@1: 0.604685\tvalid_0's ndcg@3: 0.678711\tvalid_0's ndcg@5: 0.839767\n",
            "[3]\tvalid_0's ndcg@1: 0.623785\tvalid_0's ndcg@3: 0.702421\tvalid_0's ndcg@5: 0.849932\n",
            "[4]\tvalid_0's ndcg@1: 0.631074\tvalid_0's ndcg@3: 0.712655\tvalid_0's ndcg@5: 0.854189\n",
            "[5]\tvalid_0's ndcg@1: 0.635259\tvalid_0's ndcg@3: 0.719584\tvalid_0's ndcg@5: 0.856972\n",
            "[1]\tvalid_0's ndcg@1: 0.539813\tvalid_0's ndcg@3: 0.611249\tvalid_0's ndcg@5: 0.809595\n",
            "[2]\tvalid_0's ndcg@1: 0.603373\tvalid_0's ndcg@3: 0.681971\tvalid_0's ndcg@5: 0.840448\n",
            "[3]\tvalid_0's ndcg@1: 0.620753\tvalid_0's ndcg@3: 0.70233\tvalid_0's ndcg@5: 0.849619\n",
            "[4]\tvalid_0's ndcg@1: 0.630329\tvalid_0's ndcg@3: 0.711991\tvalid_0's ndcg@5: 0.853848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:32:18,676] Trial 21 finished with value: 0.8567855860059344 and parameters: {'num_leaves': 41, 'learning_rate': 0.0764632917981984, 'max_depth': 8}. Best is trial 18 with value: 0.8573924765453034.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.635667\tvalid_0's ndcg@3: 0.718166\tvalid_0's ndcg@5: 0.856599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.53295\tvalid_0's ndcg@3: 0.609828\tvalid_0's ndcg@5: 0.807948\n",
            "[2]\tvalid_0's ndcg@1: 0.603621\tvalid_0's ndcg@3: 0.677434\tvalid_0's ndcg@5: 0.839266\n",
            "[3]\tvalid_0's ndcg@1: 0.62304\tvalid_0's ndcg@3: 0.70117\tvalid_0's ndcg@5: 0.84946\n",
            "[4]\tvalid_0's ndcg@1: 0.629105\tvalid_0's ndcg@3: 0.711553\tvalid_0's ndcg@5: 0.853682\n",
            "[5]\tvalid_0's ndcg@1: 0.636696\tvalid_0's ndcg@3: 0.718636\tvalid_0's ndcg@5: 0.857034\n",
            "[1]\tvalid_0's ndcg@1: 0.535132\tvalid_0's ndcg@3: 0.609829\tvalid_0's ndcg@5: 0.80837\n",
            "[2]\tvalid_0's ndcg@1: 0.603905\tvalid_0's ndcg@3: 0.682708\tvalid_0's ndcg@5: 0.840642\n",
            "[3]\tvalid_0's ndcg@1: 0.624087\tvalid_0's ndcg@3: 0.703703\tvalid_0's ndcg@5: 0.850325\n",
            "[4]\tvalid_0's ndcg@1: 0.63251\tvalid_0's ndcg@3: 0.714671\tvalid_0's ndcg@5: 0.854901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:32:59,772] Trial 22 finished with value: 0.8575618159566505 and parameters: {'num_leaves': 35, 'learning_rate': 0.08385931213756205, 'max_depth': 8}. Best is trial 22 with value: 0.8575618159566505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.638629\tvalid_0's ndcg@3: 0.720717\tvalid_0's ndcg@5: 0.858089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.532702\tvalid_0's ndcg@3: 0.610139\tvalid_0's ndcg@5: 0.808037\n",
            "[2]\tvalid_0's ndcg@1: 0.605076\tvalid_0's ndcg@3: 0.681647\tvalid_0's ndcg@5: 0.840909\n",
            "[3]\tvalid_0's ndcg@1: 0.622402\tvalid_0's ndcg@3: 0.704326\tvalid_0's ndcg@5: 0.850411\n",
            "[4]\tvalid_0's ndcg@1: 0.630329\tvalid_0's ndcg@3: 0.713785\tvalid_0's ndcg@5: 0.854375\n",
            "[5]\tvalid_0's ndcg@1: 0.635667\tvalid_0's ndcg@3: 0.719375\tvalid_0's ndcg@5: 0.857123\n",
            "[1]\tvalid_0's ndcg@1: 0.536657\tvalid_0's ndcg@3: 0.6103\tvalid_0's ndcg@5: 0.808718\n",
            "[2]\tvalid_0's ndcg@1: 0.606547\tvalid_0's ndcg@3: 0.681637\tvalid_0's ndcg@5: 0.840765\n",
            "[3]\tvalid_0's ndcg@1: 0.625505\tvalid_0's ndcg@3: 0.704838\tvalid_0's ndcg@5: 0.850823\n",
            "[4]\tvalid_0's ndcg@1: 0.632528\tvalid_0's ndcg@3: 0.713697\tvalid_0's ndcg@5: 0.854737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:33:41,695] Trial 23 finished with value: 0.8574154552029973 and parameters: {'num_leaves': 36, 'learning_rate': 0.08499584967742783, 'max_depth': 8}. Best is trial 22 with value: 0.8575618159566505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.636909\tvalid_0's ndcg@3: 0.720612\tvalid_0's ndcg@5: 0.857708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.518515\tvalid_0's ndcg@3: 0.580728\tvalid_0's ndcg@5: 0.79708\n",
            "[2]\tvalid_0's ndcg@1: 0.593229\tvalid_0's ndcg@3: 0.653666\tvalid_0's ndcg@5: 0.830598\n",
            "[3]\tvalid_0's ndcg@1: 0.614546\tvalid_0's ndcg@3: 0.68505\tvalid_0's ndcg@5: 0.843178\n",
            "[4]\tvalid_0's ndcg@1: 0.623856\tvalid_0's ndcg@3: 0.70184\tvalid_0's ndcg@5: 0.849897\n",
            "[5]\tvalid_0's ndcg@1: 0.631127\tvalid_0's ndcg@3: 0.711822\tvalid_0's ndcg@5: 0.853935\n",
            "[1]\tvalid_0's ndcg@1: 0.511297\tvalid_0's ndcg@3: 0.5654\tvalid_0's ndcg@5: 0.791496\n",
            "[2]\tvalid_0's ndcg@1: 0.591296\tvalid_0's ndcg@3: 0.654106\tvalid_0's ndcg@5: 0.830295\n",
            "[3]\tvalid_0's ndcg@1: 0.615858\tvalid_0's ndcg@3: 0.68782\tvalid_0's ndcg@5: 0.844284\n",
            "[4]\tvalid_0's ndcg@1: 0.626587\tvalid_0's ndcg@3: 0.701705\tvalid_0's ndcg@5: 0.850206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:34:22,564] Trial 24 finished with value: 0.8534056269538056 and parameters: {'num_leaves': 35, 'learning_rate': 0.08153970421575499, 'max_depth': 6}. Best is trial 22 with value: 0.8575618159566505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.629478\tvalid_0's ndcg@3: 0.708922\tvalid_0's ndcg@5: 0.852876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.536355\tvalid_0's ndcg@3: 0.598853\tvalid_0's ndcg@5: 0.805365\n",
            "[2]\tvalid_0's ndcg@1: 0.603923\tvalid_0's ndcg@3: 0.673664\tvalid_0's ndcg@5: 0.838379\n",
            "[3]\tvalid_0's ndcg@1: 0.622668\tvalid_0's ndcg@3: 0.697718\tvalid_0's ndcg@5: 0.848415\n",
            "[4]\tvalid_0's ndcg@1: 0.629425\tvalid_0's ndcg@3: 0.708715\tvalid_0's ndcg@5: 0.852834\n",
            "[5]\tvalid_0's ndcg@1: 0.635756\tvalid_0's ndcg@3: 0.715504\tvalid_0's ndcg@5: 0.855886\n",
            "[1]\tvalid_0's ndcg@1: 0.536586\tvalid_0's ndcg@3: 0.598949\tvalid_0's ndcg@5: 0.805447\n",
            "[2]\tvalid_0's ndcg@1: 0.601635\tvalid_0's ndcg@3: 0.671529\tvalid_0's ndcg@5: 0.837341\n",
            "[3]\tvalid_0's ndcg@1: 0.619405\tvalid_0's ndcg@3: 0.698795\tvalid_0's ndcg@5: 0.848173\n",
            "[4]\tvalid_0's ndcg@1: 0.627616\tvalid_0's ndcg@3: 0.709058\tvalid_0's ndcg@5: 0.852709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:35:03,907] Trial 25 finished with value: 0.8559165580303938 and parameters: {'num_leaves': 44, 'learning_rate': 0.07084734446816957, 'max_depth': 7}. Best is trial 22 with value: 0.8575618159566505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.636465\tvalid_0's ndcg@3: 0.715062\tvalid_0's ndcg@5: 0.855947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.489962\tvalid_0's ndcg@3: 0.55119\tvalid_0's ndcg@5: 0.783795\n",
            "[2]\tvalid_0's ndcg@1: 0.579911\tvalid_0's ndcg@3: 0.638521\tvalid_0's ndcg@5: 0.823871\n",
            "[3]\tvalid_0's ndcg@1: 0.605945\tvalid_0's ndcg@3: 0.672883\tvalid_0's ndcg@5: 0.838272\n",
            "[4]\tvalid_0's ndcg@1: 0.615964\tvalid_0's ndcg@3: 0.689776\tvalid_0's ndcg@5: 0.84491\n",
            "[5]\tvalid_0's ndcg@1: 0.625683\tvalid_0's ndcg@3: 0.70082\tvalid_0's ndcg@5: 0.84968\n",
            "[1]\tvalid_0's ndcg@1: 0.487178\tvalid_0's ndcg@3: 0.541958\tvalid_0's ndcg@5: 0.780691\n",
            "[2]\tvalid_0's ndcg@1: 0.581152\tvalid_0's ndcg@3: 0.635104\tvalid_0's ndcg@5: 0.823047\n",
            "[3]\tvalid_0's ndcg@1: 0.608658\tvalid_0's ndcg@3: 0.675754\tvalid_0's ndcg@5: 0.839446\n",
            "[4]\tvalid_0's ndcg@1: 0.623253\tvalid_0's ndcg@3: 0.694546\tvalid_0's ndcg@5: 0.847539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:35:44,670] Trial 26 finished with value: 0.8502245533238566 and parameters: {'num_leaves': 36, 'learning_rate': 0.07816159114996094, 'max_depth': 5}. Best is trial 22 with value: 0.8575618159566505.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.626374\tvalid_0's ndcg@3: 0.703391\tvalid_0's ndcg@5: 0.850769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.544389\tvalid_0's ndcg@3: 0.623026\tvalid_0's ndcg@5: 0.813727\n",
            "[2]\tvalid_0's ndcg@1: 0.606672\tvalid_0's ndcg@3: 0.686019\tvalid_0's ndcg@5: 0.842347\n",
            "[3]\tvalid_0's ndcg@1: 0.627474\tvalid_0's ndcg@3: 0.708219\tvalid_0's ndcg@5: 0.852191\n",
            "[4]\tvalid_0's ndcg@1: 0.635578\tvalid_0's ndcg@3: 0.716834\tvalid_0's ndcg@5: 0.856168\n",
            "[5]\tvalid_0's ndcg@1: 0.639054\tvalid_0's ndcg@3: 0.72222\tvalid_0's ndcg@5: 0.858276\n",
            "[1]\tvalid_0's ndcg@1: 0.544389\tvalid_0's ndcg@3: 0.624234\tvalid_0's ndcg@5: 0.814138\n",
            "[2]\tvalid_0's ndcg@1: 0.606441\tvalid_0's ndcg@3: 0.68416\tvalid_0's ndcg@5: 0.841789\n",
            "[3]\tvalid_0's ndcg@1: 0.624583\tvalid_0's ndcg@3: 0.707496\tvalid_0's ndcg@5: 0.851626\n",
            "[4]\tvalid_0's ndcg@1: 0.631907\tvalid_0's ndcg@3: 0.71583\tvalid_0's ndcg@5: 0.855535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:36:26,262] Trial 27 finished with value: 0.8585691133299633 and parameters: {'num_leaves': 44, 'learning_rate': 0.08569631388862918, 'max_depth': 9}. Best is trial 27 with value: 0.8585691133299633.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.638647\tvalid_0's ndcg@3: 0.723192\tvalid_0's ndcg@5: 0.858862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.547936\tvalid_0's ndcg@3: 0.624402\tvalid_0's ndcg@5: 0.814658\n",
            "[2]\tvalid_0's ndcg@1: 0.608605\tvalid_0's ndcg@3: 0.687028\tvalid_0's ndcg@5: 0.842878\n",
            "[3]\tvalid_0's ndcg@1: 0.626516\tvalid_0's ndcg@3: 0.707113\tvalid_0's ndcg@5: 0.851757\n",
            "[4]\tvalid_0's ndcg@1: 0.631588\tvalid_0's ndcg@3: 0.715899\tvalid_0's ndcg@5: 0.855258\n",
            "[5]\tvalid_0's ndcg@1: 0.635419\tvalid_0's ndcg@3: 0.721201\tvalid_0's ndcg@5: 0.857656\n",
            "[1]\tvalid_0's ndcg@1: 0.550614\tvalid_0's ndcg@3: 0.626716\tvalid_0's ndcg@5: 0.815948\n",
            "[2]\tvalid_0's ndcg@1: 0.611566\tvalid_0's ndcg@3: 0.686664\tvalid_0's ndcg@5: 0.843174\n",
            "[3]\tvalid_0's ndcg@1: 0.626871\tvalid_0's ndcg@3: 0.703935\tvalid_0's ndcg@5: 0.850855\n",
            "[4]\tvalid_0's ndcg@1: 0.635135\tvalid_0's ndcg@3: 0.7149\tvalid_0's ndcg@5: 0.855398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:37:07,646] Trial 28 finished with value: 0.8578574777643865 and parameters: {'num_leaves': 49, 'learning_rate': 0.06689171349562131, 'max_depth': 9}. Best is trial 27 with value: 0.8585691133299633.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.639054\tvalid_0's ndcg@3: 0.720853\tvalid_0's ndcg@5: 0.858059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.547936\tvalid_0's ndcg@3: 0.624402\tvalid_0's ndcg@5: 0.814658\n",
            "[2]\tvalid_0's ndcg@1: 0.608356\tvalid_0's ndcg@3: 0.686966\tvalid_0's ndcg@5: 0.842821\n",
            "[3]\tvalid_0's ndcg@1: 0.626463\tvalid_0's ndcg@3: 0.707077\tvalid_0's ndcg@5: 0.851718\n",
            "[4]\tvalid_0's ndcg@1: 0.632174\tvalid_0's ndcg@3: 0.716056\tvalid_0's ndcg@5: 0.855443\n",
            "[5]\tvalid_0's ndcg@1: 0.637228\tvalid_0's ndcg@3: 0.720248\tvalid_0's ndcg@5: 0.857579\n",
            "[1]\tvalid_0's ndcg@1: 0.550614\tvalid_0's ndcg@3: 0.626716\tvalid_0's ndcg@5: 0.815948\n",
            "[2]\tvalid_0's ndcg@1: 0.611673\tvalid_0's ndcg@3: 0.686685\tvalid_0's ndcg@5: 0.843193\n",
            "[3]\tvalid_0's ndcg@1: 0.626835\tvalid_0's ndcg@3: 0.703967\tvalid_0's ndcg@5: 0.850851\n",
            "[4]\tvalid_0's ndcg@1: 0.634621\tvalid_0's ndcg@3: 0.714734\tvalid_0's ndcg@5: 0.855234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:37:49,985] Trial 29 finished with value: 0.8579316072301284 and parameters: {'num_leaves': 49, 'learning_rate': 0.0653824927840243, 'max_depth': 9}. Best is trial 27 with value: 0.8585691133299633.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.640899\tvalid_0's ndcg@3: 0.721633\tvalid_0's ndcg@5: 0.858285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.550046\tvalid_0's ndcg@3: 0.625046\tvalid_0's ndcg@5: 0.815164\n",
            "[2]\tvalid_0's ndcg@1: 0.61263\tvalid_0's ndcg@3: 0.688035\tvalid_0's ndcg@5: 0.84376\n",
            "[3]\tvalid_0's ndcg@1: 0.628414\tvalid_0's ndcg@3: 0.707765\tvalid_0's ndcg@5: 0.852213\n",
            "[4]\tvalid_0's ndcg@1: 0.631163\tvalid_0's ndcg@3: 0.712659\tvalid_0's ndcg@5: 0.854176\n",
            "[5]\tvalid_0's ndcg@1: 0.634692\tvalid_0's ndcg@3: 0.718175\tvalid_0's ndcg@5: 0.856483\n",
            "[1]\tvalid_0's ndcg@1: 0.550117\tvalid_0's ndcg@3: 0.626599\tvalid_0's ndcg@5: 0.815864\n",
            "[2]\tvalid_0's ndcg@1: 0.609704\tvalid_0's ndcg@3: 0.689191\tvalid_0's ndcg@5: 0.843747\n",
            "[3]\tvalid_0's ndcg@1: 0.62531\tvalid_0's ndcg@3: 0.705434\tvalid_0's ndcg@5: 0.851527\n",
            "[4]\tvalid_0's ndcg@1: 0.633947\tvalid_0's ndcg@3: 0.714325\tvalid_0's ndcg@5: 0.855322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:38:32,607] Trial 30 finished with value: 0.8570479708111938 and parameters: {'num_leaves': 50, 'learning_rate': 0.04745529327210386, 'max_depth': 9}. Best is trial 27 with value: 0.8585691133299633.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.638097\tvalid_0's ndcg@3: 0.72042\tvalid_0's ndcg@5: 0.857613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.548042\tvalid_0's ndcg@3: 0.624595\tvalid_0's ndcg@5: 0.814754\n",
            "[2]\tvalid_0's ndcg@1: 0.610591\tvalid_0's ndcg@3: 0.687309\tvalid_0's ndcg@5: 0.843181\n",
            "[3]\tvalid_0's ndcg@1: 0.629052\tvalid_0's ndcg@3: 0.706811\tvalid_0's ndcg@5: 0.852008\n",
            "[4]\tvalid_0's ndcg@1: 0.634231\tvalid_0's ndcg@3: 0.716697\tvalid_0's ndcg@5: 0.855879\n",
            "[5]\tvalid_0's ndcg@1: 0.636199\tvalid_0's ndcg@3: 0.720759\tvalid_0's ndcg@5: 0.857479\n",
            "[1]\tvalid_0's ndcg@1: 0.546357\tvalid_0's ndcg@3: 0.62509\tvalid_0's ndcg@5: 0.814749\n",
            "[2]\tvalid_0's ndcg@1: 0.608693\tvalid_0's ndcg@3: 0.686349\tvalid_0's ndcg@5: 0.842531\n",
            "[3]\tvalid_0's ndcg@1: 0.623998\tvalid_0's ndcg@3: 0.70428\tvalid_0's ndcg@5: 0.850649\n",
            "[4]\tvalid_0's ndcg@1: 0.632635\tvalid_0's ndcg@3: 0.714735\tvalid_0's ndcg@5: 0.855325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:39:14,092] Trial 31 finished with value: 0.8576659409179511 and parameters: {'num_leaves': 48, 'learning_rate': 0.06477663069177061, 'max_depth': 9}. Best is trial 27 with value: 0.8585691133299633.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.637848\tvalid_0's ndcg@3: 0.720767\tvalid_0's ndcg@5: 0.857853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.550046\tvalid_0's ndcg@3: 0.625046\tvalid_0's ndcg@5: 0.815164\n",
            "[2]\tvalid_0's ndcg@1: 0.613003\tvalid_0's ndcg@3: 0.688437\tvalid_0's ndcg@5: 0.843821\n",
            "[3]\tvalid_0's ndcg@1: 0.625434\tvalid_0's ndcg@3: 0.70696\tvalid_0's ndcg@5: 0.851542\n",
            "[4]\tvalid_0's ndcg@1: 0.632315\tvalid_0's ndcg@3: 0.714653\tvalid_0's ndcg@5: 0.855128\n",
            "[5]\tvalid_0's ndcg@1: 0.638735\tvalid_0's ndcg@3: 0.721738\tvalid_0's ndcg@5: 0.858231\n",
            "[1]\tvalid_0's ndcg@1: 0.550117\tvalid_0's ndcg@3: 0.626599\tvalid_0's ndcg@5: 0.815864\n",
            "[2]\tvalid_0's ndcg@1: 0.610431\tvalid_0's ndcg@3: 0.688435\tvalid_0's ndcg@5: 0.843494\n",
            "[3]\tvalid_0's ndcg@1: 0.626481\tvalid_0's ndcg@3: 0.705679\tvalid_0's ndcg@5: 0.851311\n",
            "[4]\tvalid_0's ndcg@1: 0.634053\tvalid_0's ndcg@3: 0.715172\tvalid_0's ndcg@5: 0.855636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:39:55,861] Trial 32 finished with value: 0.8580194921255182 and parameters: {'num_leaves': 50, 'learning_rate': 0.06541084346271667, 'max_depth': 9}. Best is trial 27 with value: 0.8585691133299633.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.638026\tvalid_0's ndcg@3: 0.721205\tvalid_0's ndcg@5: 0.857808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.541906\tvalid_0's ndcg@3: 0.656678\tvalid_0's ndcg@5: 0.823057\n",
            "[2]\tvalid_0's ndcg@1: 0.606689\tvalid_0's ndcg@3: 0.703323\tvalid_0's ndcg@5: 0.847909\n",
            "[3]\tvalid_0's ndcg@1: 0.625931\tvalid_0's ndcg@3: 0.715774\tvalid_0's ndcg@5: 0.855023\n",
            "[4]\tvalid_0's ndcg@1: 0.635082\tvalid_0's ndcg@3: 0.72265\tvalid_0's ndcg@5: 0.858352\n",
            "[5]\tvalid_0's ndcg@1: 0.635135\tvalid_0's ndcg@3: 0.725211\tvalid_0's ndcg@5: 0.858996\n",
            "[1]\tvalid_0's ndcg@1: 0.544442\tvalid_0's ndcg@3: 0.659515\tvalid_0's ndcg@5: 0.82466\n",
            "[2]\tvalid_0's ndcg@1: 0.610307\tvalid_0's ndcg@3: 0.707212\tvalid_0's ndcg@5: 0.849544\n",
            "[3]\tvalid_0's ndcg@1: 0.624991\tvalid_0's ndcg@3: 0.716784\tvalid_0's ndcg@5: 0.854993\n",
            "[4]\tvalid_0's ndcg@1: 0.633113\tvalid_0's ndcg@3: 0.723213\tvalid_0's ndcg@5: 0.858119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:40:38,279] Trial 33 finished with value: 0.8594888026805935 and parameters: {'num_leaves': 44, 'learning_rate': 0.06518640195332566, 'max_depth': -1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.638753\tvalid_0's ndcg@3: 0.72578\tvalid_0's ndcg@5: 0.859982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.541906\tvalid_0's ndcg@3: 0.656678\tvalid_0's ndcg@5: 0.823057\n",
            "[2]\tvalid_0's ndcg@1: 0.608764\tvalid_0's ndcg@3: 0.703934\tvalid_0's ndcg@5: 0.848487\n",
            "[3]\tvalid_0's ndcg@1: 0.622739\tvalid_0's ndcg@3: 0.714409\tvalid_0's ndcg@5: 0.853908\n",
            "[4]\tvalid_0's ndcg@1: 0.630471\tvalid_0's ndcg@3: 0.72\tvalid_0's ndcg@5: 0.856686\n",
            "[5]\tvalid_0's ndcg@1: 0.632298\tvalid_0's ndcg@3: 0.72214\tvalid_0's ndcg@5: 0.857747\n",
            "[1]\tvalid_0's ndcg@1: 0.544442\tvalid_0's ndcg@3: 0.659515\tvalid_0's ndcg@5: 0.82466\n",
            "[2]\tvalid_0's ndcg@1: 0.608924\tvalid_0's ndcg@3: 0.705658\tvalid_0's ndcg@5: 0.84893\n",
            "[3]\tvalid_0's ndcg@1: 0.622969\tvalid_0's ndcg@3: 0.714834\tvalid_0's ndcg@5: 0.854051\n",
            "[4]\tvalid_0's ndcg@1: 0.630489\tvalid_0's ndcg@3: 0.722022\tvalid_0's ndcg@5: 0.85722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:41:20,386] Trial 34 finished with value: 0.8584452946726566 and parameters: {'num_leaves': 44, 'learning_rate': 0.03668922893838933, 'max_depth': -1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.635383\tvalid_0's ndcg@3: 0.725221\tvalid_0's ndcg@5: 0.859144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.541906\tvalid_0's ndcg@3: 0.656678\tvalid_0's ndcg@5: 0.823057\n",
            "[2]\tvalid_0's ndcg@1: 0.608392\tvalid_0's ndcg@3: 0.703716\tvalid_0's ndcg@5: 0.848349\n",
            "[3]\tvalid_0's ndcg@1: 0.623431\tvalid_0's ndcg@3: 0.71487\tvalid_0's ndcg@5: 0.854182\n",
            "[4]\tvalid_0's ndcg@1: 0.62946\tvalid_0's ndcg@3: 0.720021\tvalid_0's ndcg@5: 0.856409\n",
            "[5]\tvalid_0's ndcg@1: 0.630542\tvalid_0's ndcg@3: 0.721747\tvalid_0's ndcg@5: 0.857135\n",
            "[1]\tvalid_0's ndcg@1: 0.544442\tvalid_0's ndcg@3: 0.659515\tvalid_0's ndcg@5: 0.82466\n",
            "[2]\tvalid_0's ndcg@1: 0.608569\tvalid_0's ndcg@3: 0.705607\tvalid_0's ndcg@5: 0.84888\n",
            "[3]\tvalid_0's ndcg@1: 0.622384\tvalid_0's ndcg@3: 0.714662\tvalid_0's ndcg@5: 0.853821\n",
            "[4]\tvalid_0's ndcg@1: 0.631961\tvalid_0's ndcg@3: 0.722098\tvalid_0's ndcg@5: 0.857435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:42:02,241] Trial 35 finished with value: 0.8579547343363024 and parameters: {'num_leaves': 44, 'learning_rate': 0.03575492546807886, 'max_depth': -1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.635295\tvalid_0's ndcg@3: 0.72444\tvalid_0's ndcg@5: 0.858775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.541906\tvalid_0's ndcg@3: 0.656678\tvalid_0's ndcg@5: 0.823057\n",
            "[2]\tvalid_0's ndcg@1: 0.610343\tvalid_0's ndcg@3: 0.704738\tvalid_0's ndcg@5: 0.848953\n",
            "[3]\tvalid_0's ndcg@1: 0.623821\tvalid_0's ndcg@3: 0.714964\tvalid_0's ndcg@5: 0.8541\n",
            "[4]\tvalid_0's ndcg@1: 0.631198\tvalid_0's ndcg@3: 0.719531\tvalid_0's ndcg@5: 0.856562\n",
            "[5]\tvalid_0's ndcg@1: 0.635117\tvalid_0's ndcg@3: 0.722728\tvalid_0's ndcg@5: 0.85819\n",
            "[1]\tvalid_0's ndcg@1: 0.544442\tvalid_0's ndcg@3: 0.659515\tvalid_0's ndcg@5: 0.82466\n",
            "[2]\tvalid_0's ndcg@1: 0.607647\tvalid_0's ndcg@3: 0.705414\tvalid_0's ndcg@5: 0.84869\n",
            "[3]\tvalid_0's ndcg@1: 0.621125\tvalid_0's ndcg@3: 0.7161\tvalid_0's ndcg@5: 0.853974\n",
            "[4]\tvalid_0's ndcg@1: 0.632989\tvalid_0's ndcg@3: 0.722927\tvalid_0's ndcg@5: 0.857953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:42:44,468] Trial 36 finished with value: 0.8588180772690727 and parameters: {'num_leaves': 44, 'learning_rate': 0.04823515599966561, 'max_depth': -1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.637405\tvalid_0's ndcg@3: 0.726193\tvalid_0's ndcg@5: 0.859446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.541906\tvalid_0's ndcg@3: 0.656678\tvalid_0's ndcg@5: 0.823057\n",
            "[2]\tvalid_0's ndcg@1: 0.60825\tvalid_0's ndcg@3: 0.703651\tvalid_0's ndcg@5: 0.848303\n",
            "[3]\tvalid_0's ndcg@1: 0.62226\tvalid_0's ndcg@3: 0.71362\tvalid_0's ndcg@5: 0.853869\n",
            "[4]\tvalid_0's ndcg@1: 0.630134\tvalid_0's ndcg@3: 0.718734\tvalid_0's ndcg@5: 0.856413\n",
            "[5]\tvalid_0's ndcg@1: 0.634195\tvalid_0's ndcg@3: 0.722255\tvalid_0's ndcg@5: 0.858062\n",
            "[1]\tvalid_0's ndcg@1: 0.544442\tvalid_0's ndcg@3: 0.659515\tvalid_0's ndcg@5: 0.82466\n",
            "[2]\tvalid_0's ndcg@1: 0.607576\tvalid_0's ndcg@3: 0.705601\tvalid_0's ndcg@5: 0.848747\n",
            "[3]\tvalid_0's ndcg@1: 0.621639\tvalid_0's ndcg@3: 0.713709\tvalid_0's ndcg@5: 0.853518\n",
            "[4]\tvalid_0's ndcg@1: 0.627048\tvalid_0's ndcg@3: 0.717875\tvalid_0's ndcg@5: 0.855696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:43:26,384] Trial 37 finished with value: 0.8581609595838992 and parameters: {'num_leaves': 44, 'learning_rate': 0.03338187978531596, 'max_depth': -1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.634763\tvalid_0's ndcg@3: 0.722447\tvalid_0's ndcg@5: 0.85826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.543946\tvalid_0's ndcg@3: 0.657093\tvalid_0's ndcg@5: 0.823597\n",
            "[2]\tvalid_0's ndcg@1: 0.609952\tvalid_0's ndcg@3: 0.704445\tvalid_0's ndcg@5: 0.848678\n",
            "[3]\tvalid_0's ndcg@1: 0.622969\tvalid_0's ndcg@3: 0.715975\tvalid_0's ndcg@5: 0.854099\n",
            "[4]\tvalid_0's ndcg@1: 0.630099\tvalid_0's ndcg@3: 0.719861\tvalid_0's ndcg@5: 0.856364\n",
            "[5]\tvalid_0's ndcg@1: 0.634124\tvalid_0's ndcg@3: 0.723555\tvalid_0's ndcg@5: 0.85836\n",
            "[1]\tvalid_0's ndcg@1: 0.545169\tvalid_0's ndcg@3: 0.660479\tvalid_0's ndcg@5: 0.82515\n",
            "[2]\tvalid_0's ndcg@1: 0.607452\tvalid_0's ndcg@3: 0.706177\tvalid_0's ndcg@5: 0.848931\n",
            "[3]\tvalid_0's ndcg@1: 0.621409\tvalid_0's ndcg@3: 0.716024\tvalid_0's ndcg@5: 0.853973\n",
            "[4]\tvalid_0's ndcg@1: 0.631322\tvalid_0's ndcg@3: 0.721864\tvalid_0's ndcg@5: 0.857433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:44:09,144] Trial 38 finished with value: 0.8587144031294337 and parameters: {'num_leaves': 46, 'learning_rate': 0.041675443344502294, 'max_depth': 0}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.637281\tvalid_0's ndcg@3: 0.723922\tvalid_0's ndcg@5: 0.859068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.543946\tvalid_0's ndcg@3: 0.657093\tvalid_0's ndcg@5: 0.823597\n",
            "[2]\tvalid_0's ndcg@1: 0.610662\tvalid_0's ndcg@3: 0.704799\tvalid_0's ndcg@5: 0.848806\n",
            "[3]\tvalid_0's ndcg@1: 0.623182\tvalid_0's ndcg@3: 0.714777\tvalid_0's ndcg@5: 0.85418\n",
            "[4]\tvalid_0's ndcg@1: 0.62907\tvalid_0's ndcg@3: 0.720618\tvalid_0's ndcg@5: 0.856597\n",
            "[5]\tvalid_0's ndcg@1: 0.633681\tvalid_0's ndcg@3: 0.723764\tvalid_0's ndcg@5: 0.858352\n",
            "[1]\tvalid_0's ndcg@1: 0.545169\tvalid_0's ndcg@3: 0.660479\tvalid_0's ndcg@5: 0.82515\n",
            "[2]\tvalid_0's ndcg@1: 0.607097\tvalid_0's ndcg@3: 0.70578\tvalid_0's ndcg@5: 0.848777\n",
            "[3]\tvalid_0's ndcg@1: 0.620983\tvalid_0's ndcg@3: 0.715835\tvalid_0's ndcg@5: 0.853681\n",
            "[4]\tvalid_0's ndcg@1: 0.63134\tvalid_0's ndcg@3: 0.722254\tvalid_0's ndcg@5: 0.857296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:44:51,173] Trial 39 finished with value: 0.8587822510008256 and parameters: {'num_leaves': 46, 'learning_rate': 0.04335625150471052, 'max_depth': 0}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.636554\tvalid_0's ndcg@3: 0.725435\tvalid_0's ndcg@5: 0.859212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.543946\tvalid_0's ndcg@3: 0.657093\tvalid_0's ndcg@5: 0.823597\n",
            "[2]\tvalid_0's ndcg@1: 0.607541\tvalid_0's ndcg@3: 0.704331\tvalid_0's ndcg@5: 0.848469\n",
            "[3]\tvalid_0's ndcg@1: 0.61749\tvalid_0's ndcg@3: 0.712401\tvalid_0's ndcg@5: 0.852279\n",
            "[4]\tvalid_0's ndcg@1: 0.625967\tvalid_0's ndcg@3: 0.717734\tvalid_0's ndcg@5: 0.855196\n",
            "[5]\tvalid_0's ndcg@1: 0.630595\tvalid_0's ndcg@3: 0.720903\tvalid_0's ndcg@5: 0.856907\n",
            "[1]\tvalid_0's ndcg@1: 0.545169\tvalid_0's ndcg@3: 0.660479\tvalid_0's ndcg@5: 0.82515\n",
            "[2]\tvalid_0's ndcg@1: 0.605749\tvalid_0's ndcg@3: 0.704379\tvalid_0's ndcg@5: 0.848058\n",
            "[3]\tvalid_0's ndcg@1: 0.624424\tvalid_0's ndcg@3: 0.71524\tvalid_0's ndcg@5: 0.854196\n",
            "[4]\tvalid_0's ndcg@1: 0.631429\tvalid_0's ndcg@3: 0.720574\tvalid_0's ndcg@5: 0.85698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:45:32,254] Trial 40 finished with value: 0.8576842631347996 and parameters: {'num_leaves': 46, 'learning_rate': 0.029396861764835455, 'max_depth': 0}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.634514\tvalid_0's ndcg@3: 0.723899\tvalid_0's ndcg@5: 0.858461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.543946\tvalid_0's ndcg@3: 0.657093\tvalid_0's ndcg@5: 0.823597\n",
            "[2]\tvalid_0's ndcg@1: 0.610609\tvalid_0's ndcg@3: 0.704755\tvalid_0's ndcg@5: 0.848786\n",
            "[3]\tvalid_0's ndcg@1: 0.623537\tvalid_0's ndcg@3: 0.715588\tvalid_0's ndcg@5: 0.854279\n",
            "[4]\tvalid_0's ndcg@1: 0.629886\tvalid_0's ndcg@3: 0.719649\tvalid_0's ndcg@5: 0.856624\n",
            "[5]\tvalid_0's ndcg@1: 0.637919\tvalid_0's ndcg@3: 0.723913\tvalid_0's ndcg@5: 0.859266\n",
            "[1]\tvalid_0's ndcg@1: 0.545169\tvalid_0's ndcg@3: 0.660479\tvalid_0's ndcg@5: 0.82515\n",
            "[2]\tvalid_0's ndcg@1: 0.60747\tvalid_0's ndcg@3: 0.70574\tvalid_0's ndcg@5: 0.848849\n",
            "[3]\tvalid_0's ndcg@1: 0.620983\tvalid_0's ndcg@3: 0.715555\tvalid_0's ndcg@5: 0.853598\n",
            "[4]\tvalid_0's ndcg@1: 0.632635\tvalid_0's ndcg@3: 0.721102\tvalid_0's ndcg@5: 0.857384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:46:13,271] Trial 41 finished with value: 0.8590565845634348 and parameters: {'num_leaves': 46, 'learning_rate': 0.04397133158783335, 'max_depth': 0}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.635277\tvalid_0's ndcg@3: 0.724122\tvalid_0's ndcg@5: 0.858847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.183355\tvalid_0's ndcg@3: 0.332443\tvalid_0's ndcg@5: 0.668818\n",
            "[2]\tvalid_0's ndcg@1: 0.298858\tvalid_0's ndcg@3: 0.402918\tvalid_0's ndcg@5: 0.708597\n",
            "[3]\tvalid_0's ndcg@1: 0.367738\tvalid_0's ndcg@3: 0.444987\tvalid_0's ndcg@5: 0.732162\n",
            "[4]\tvalid_0's ndcg@1: 0.422182\tvalid_0's ndcg@3: 0.483674\tvalid_0's ndcg@5: 0.752586\n",
            "[5]\tvalid_0's ndcg@1: 0.461747\tvalid_0's ndcg@3: 0.519371\tvalid_0's ndcg@5: 0.769598\n",
            "[1]\tvalid_0's ndcg@1: 0.168529\tvalid_0's ndcg@3: 0.323784\tvalid_0's ndcg@5: 0.663856\n",
            "[2]\tvalid_0's ndcg@1: 0.288146\tvalid_0's ndcg@3: 0.395031\tvalid_0's ndcg@5: 0.704486\n",
            "[3]\tvalid_0's ndcg@1: 0.374104\tvalid_0's ndcg@3: 0.452523\tvalid_0's ndcg@5: 0.735611\n",
            "[4]\tvalid_0's ndcg@1: 0.425374\tvalid_0's ndcg@3: 0.492152\tvalid_0's ndcg@5: 0.755804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:46:53,185] Trial 42 finished with value: 0.7709053525239912 and parameters: {'num_leaves': 46, 'learning_rate': 0.045465442434191, 'max_depth': 1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.467759\tvalid_0's ndcg@3: 0.524164\tvalid_0's ndcg@5: 0.772213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.545027\tvalid_0's ndcg@3: 0.657042\tvalid_0's ndcg@5: 0.823795\n",
            "[2]\tvalid_0's ndcg@1: 0.608516\tvalid_0's ndcg@3: 0.704194\tvalid_0's ndcg@5: 0.848425\n",
            "[3]\tvalid_0's ndcg@1: 0.625559\tvalid_0's ndcg@3: 0.714889\tvalid_0's ndcg@5: 0.854306\n",
            "[4]\tvalid_0's ndcg@1: 0.632174\tvalid_0's ndcg@3: 0.719629\tvalid_0's ndcg@5: 0.857025\n",
            "[5]\tvalid_0's ndcg@1: 0.633539\tvalid_0's ndcg@3: 0.723136\tvalid_0's ndcg@5: 0.85822\n",
            "[1]\tvalid_0's ndcg@1: 0.54712\tvalid_0's ndcg@3: 0.661069\tvalid_0's ndcg@5: 0.825651\n",
            "[2]\tvalid_0's ndcg@1: 0.607736\tvalid_0's ndcg@3: 0.705968\tvalid_0's ndcg@5: 0.849041\n",
            "[3]\tvalid_0's ndcg@1: 0.62187\tvalid_0's ndcg@3: 0.716173\tvalid_0's ndcg@5: 0.854193\n",
            "[4]\tvalid_0's ndcg@1: 0.629123\tvalid_0's ndcg@3: 0.721102\tvalid_0's ndcg@5: 0.856942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:47:35,207] Trial 43 finished with value: 0.8589044614213843 and parameters: {'num_leaves': 47, 'learning_rate': 0.04070484975475853, 'max_depth': 0}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.636784\tvalid_0's ndcg@3: 0.726393\tvalid_0's ndcg@5: 0.859589\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.540292\tvalid_0's ndcg@3: 0.655392\tvalid_0's ndcg@5: 0.822449\n",
            "[2]\tvalid_0's ndcg@1: 0.605235\tvalid_0's ndcg@3: 0.70338\tvalid_0's ndcg@5: 0.847687\n",
            "[3]\tvalid_0's ndcg@1: 0.624175\tvalid_0's ndcg@3: 0.715576\tvalid_0's ndcg@5: 0.854475\n",
            "[4]\tvalid_0's ndcg@1: 0.631056\tvalid_0's ndcg@3: 0.720845\tvalid_0's ndcg@5: 0.857049\n",
            "[5]\tvalid_0's ndcg@1: 0.635188\tvalid_0's ndcg@3: 0.724927\tvalid_0's ndcg@5: 0.85894\n",
            "[1]\tvalid_0's ndcg@1: 0.541995\tvalid_0's ndcg@3: 0.65834\tvalid_0's ndcg@5: 0.824057\n",
            "[2]\tvalid_0's ndcg@1: 0.608942\tvalid_0's ndcg@3: 0.706365\tvalid_0's ndcg@5: 0.849283\n",
            "[3]\tvalid_0's ndcg@1: 0.62375\tvalid_0's ndcg@3: 0.7152\tvalid_0's ndcg@5: 0.854423\n",
            "[4]\tvalid_0's ndcg@1: 0.633238\tvalid_0's ndcg@3: 0.720952\tvalid_0's ndcg@5: 0.85753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:48:19,037] Trial 44 finished with value: 0.8589627533486262 and parameters: {'num_leaves': 42, 'learning_rate': 0.049971782058025264, 'max_depth': 0}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.636341\tvalid_0's ndcg@3: 0.723994\tvalid_0's ndcg@5: 0.858985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.183355\tvalid_0's ndcg@3: 0.332443\tvalid_0's ndcg@5: 0.668818\n",
            "[2]\tvalid_0's ndcg@1: 0.298858\tvalid_0's ndcg@3: 0.402918\tvalid_0's ndcg@5: 0.708597\n",
            "[3]\tvalid_0's ndcg@1: 0.367738\tvalid_0's ndcg@3: 0.444987\tvalid_0's ndcg@5: 0.732162\n",
            "[4]\tvalid_0's ndcg@1: 0.426651\tvalid_0's ndcg@3: 0.489762\tvalid_0's ndcg@5: 0.755205\n",
            "[5]\tvalid_0's ndcg@1: 0.469302\tvalid_0's ndcg@3: 0.523785\tvalid_0's ndcg@5: 0.772264\n",
            "[1]\tvalid_0's ndcg@1: 0.168529\tvalid_0's ndcg@3: 0.323784\tvalid_0's ndcg@5: 0.663856\n",
            "[2]\tvalid_0's ndcg@1: 0.288146\tvalid_0's ndcg@3: 0.395031\tvalid_0's ndcg@5: 0.704486\n",
            "[3]\tvalid_0's ndcg@1: 0.374104\tvalid_0's ndcg@3: 0.452523\tvalid_0's ndcg@5: 0.735611\n",
            "[4]\tvalid_0's ndcg@1: 0.425374\tvalid_0's ndcg@3: 0.492152\tvalid_0's ndcg@5: 0.755804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:49:02,894] Trial 45 finished with value: 0.7722381166633832 and parameters: {'num_leaves': 42, 'learning_rate': 0.049672875242655866, 'max_depth': 1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.467759\tvalid_0's ndcg@3: 0.524164\tvalid_0's ndcg@5: 0.772213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.305597\tvalid_0's ndcg@3: 0.405798\tvalid_0's ndcg@5: 0.710563\n",
            "[2]\tvalid_0's ndcg@1: 0.41977\tvalid_0's ndcg@3: 0.484742\tvalid_0's ndcg@5: 0.752728\n",
            "[3]\tvalid_0's ndcg@1: 0.489413\tvalid_0's ndcg@3: 0.539247\tvalid_0's ndcg@5: 0.779995\n",
            "[4]\tvalid_0's ndcg@1: 0.533589\tvalid_0's ndcg@3: 0.576342\tvalid_0's ndcg@5: 0.798278\n",
            "[5]\tvalid_0's ndcg@1: 0.562247\tvalid_0's ndcg@3: 0.608092\tvalid_0's ndcg@5: 0.812364\n",
            "[1]\tvalid_0's ndcg@1: 0.284192\tvalid_0's ndcg@3: 0.391073\tvalid_0's ndcg@5: 0.702772\n",
            "[2]\tvalid_0's ndcg@1: 0.430056\tvalid_0's ndcg@3: 0.495034\tvalid_0's ndcg@5: 0.757429\n",
            "[3]\tvalid_0's ndcg@1: 0.505125\tvalid_0's ndcg@3: 0.554439\tvalid_0's ndcg@5: 0.787179\n",
            "[4]\tvalid_0's ndcg@1: 0.548237\tvalid_0's ndcg@3: 0.594989\tvalid_0's ndcg@5: 0.806063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:49:43,093] Trial 46 finished with value: 0.8156303367496048 and parameters: {'num_leaves': 38, 'learning_rate': 0.05016358245135047, 'max_depth': 2}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.573526\tvalid_0's ndcg@3: 0.624279\tvalid_0's ndcg@5: 0.818897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.540665\tvalid_0's ndcg@3: 0.655685\tvalid_0's ndcg@5: 0.822587\n",
            "[2]\tvalid_0's ndcg@1: 0.609225\tvalid_0's ndcg@3: 0.704757\tvalid_0's ndcg@5: 0.848698\n",
            "[3]\tvalid_0's ndcg@1: 0.621054\tvalid_0's ndcg@3: 0.714761\tvalid_0's ndcg@5: 0.853536\n",
            "[4]\tvalid_0's ndcg@1: 0.62664\tvalid_0's ndcg@3: 0.718724\tvalid_0's ndcg@5: 0.855706\n",
            "[5]\tvalid_0's ndcg@1: 0.629159\tvalid_0's ndcg@3: 0.721456\tvalid_0's ndcg@5: 0.857087\n",
            "[1]\tvalid_0's ndcg@1: 0.542066\tvalid_0's ndcg@3: 0.658707\tvalid_0's ndcg@5: 0.824099\n",
            "[2]\tvalid_0's ndcg@1: 0.608285\tvalid_0's ndcg@3: 0.705347\tvalid_0's ndcg@5: 0.848637\n",
            "[3]\tvalid_0's ndcg@1: 0.62226\tvalid_0's ndcg@3: 0.71527\tvalid_0's ndcg@5: 0.85414\n",
            "[4]\tvalid_0's ndcg@1: 0.631021\tvalid_0's ndcg@3: 0.721428\tvalid_0's ndcg@5: 0.857071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:50:27,146] Trial 47 finished with value: 0.8574827366379532 and parameters: {'num_leaves': 43, 'learning_rate': 0.039870529395372105, 'max_depth': 0}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.631677\tvalid_0's ndcg@3: 0.723454\tvalid_0's ndcg@5: 0.857878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.305597\tvalid_0's ndcg@3: 0.405798\tvalid_0's ndcg@5: 0.710563\n",
            "[2]\tvalid_0's ndcg@1: 0.41977\tvalid_0's ndcg@3: 0.484742\tvalid_0's ndcg@5: 0.752728\n",
            "[3]\tvalid_0's ndcg@1: 0.489413\tvalid_0's ndcg@3: 0.539248\tvalid_0's ndcg@5: 0.779997\n",
            "[4]\tvalid_0's ndcg@1: 0.533642\tvalid_0's ndcg@3: 0.576345\tvalid_0's ndcg@5: 0.798294\n",
            "[5]\tvalid_0's ndcg@1: 0.562141\tvalid_0's ndcg@3: 0.609367\tvalid_0's ndcg@5: 0.812544\n",
            "[1]\tvalid_0's ndcg@1: 0.284192\tvalid_0's ndcg@3: 0.391073\tvalid_0's ndcg@5: 0.702772\n",
            "[2]\tvalid_0's ndcg@1: 0.430056\tvalid_0's ndcg@3: 0.495034\tvalid_0's ndcg@5: 0.757429\n",
            "[3]\tvalid_0's ndcg@1: 0.505125\tvalid_0's ndcg@3: 0.554439\tvalid_0's ndcg@5: 0.787179\n",
            "[4]\tvalid_0's ndcg@1: 0.548237\tvalid_0's ndcg@3: 0.594989\tvalid_0's ndcg@5: 0.806063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:51:05,939] Trial 48 finished with value: 0.8157365717948482 and parameters: {'num_leaves': 38, 'learning_rate': 0.05436047723526783, 'max_depth': 2}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.573615\tvalid_0's ndcg@3: 0.62433\tvalid_0's ndcg@5: 0.818929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-94-df06586a13cd>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.183355\tvalid_0's ndcg@3: 0.332443\tvalid_0's ndcg@5: 0.668818\n",
            "[2]\tvalid_0's ndcg@1: 0.298858\tvalid_0's ndcg@3: 0.402918\tvalid_0's ndcg@5: 0.708597\n",
            "[3]\tvalid_0's ndcg@1: 0.371036\tvalid_0's ndcg@3: 0.455565\tvalid_0's ndcg@5: 0.736114\n",
            "[4]\tvalid_0's ndcg@1: 0.432078\tvalid_0's ndcg@3: 0.498921\tvalid_0's ndcg@5: 0.758898\n",
            "[5]\tvalid_0's ndcg@1: 0.472405\tvalid_0's ndcg@3: 0.530285\tvalid_0's ndcg@5: 0.774722\n",
            "[1]\tvalid_0's ndcg@1: 0.168529\tvalid_0's ndcg@3: 0.323784\tvalid_0's ndcg@5: 0.663856\n",
            "[2]\tvalid_0's ndcg@1: 0.288146\tvalid_0's ndcg@3: 0.395031\tvalid_0's ndcg@5: 0.704486\n",
            "[3]\tvalid_0's ndcg@1: 0.374104\tvalid_0's ndcg@3: 0.452523\tvalid_0's ndcg@5: 0.735611\n",
            "[4]\tvalid_0's ndcg@1: 0.425374\tvalid_0's ndcg@3: 0.492152\tvalid_0's ndcg@5: 0.755804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-24 02:51:48,533] Trial 49 finished with value: 0.7734672778693916 and parameters: {'num_leaves': 47, 'learning_rate': 0.05779104016866895, 'max_depth': 1}. Best is trial 33 with value: 0.8594888026805935.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5]\tvalid_0's ndcg@1: 0.467759\tvalid_0's ndcg@3: 0.524164\tvalid_0's ndcg@5: 0.772213\n",
            "Best trial:\n",
            "NDCG: 0.8594888026805935\n",
            "Hyperparameters: {'num_leaves': 44, 'learning_rate': 0.06518640195332566, 'max_depth': -1}\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "def objective(trial, X, y):\n",
        "    params = {\n",
        "        'objective': 'lambdarank',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_estimators': 5,\n",
        "        'importance_type': 'gain',\n",
        "        'metric': 'ndcg',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 50),\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
        "        'max_depth': trial.suggest_int('max_depth', -1, 10),\n",
        "        'label_gain': [i for i in range(5)]\n",
        "    }\n",
        "\n",
        "    cv = GroupShuffleSplit(test_size=0.2, n_splits=2, random_state=42)\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y, groups=X['qid'])):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        ranker = lgb.LGBMRanker(**params)\n",
        "\n",
        "        qids_train = X_train.groupby('qid')['qid'].count().to_numpy()\n",
        "        qids_test = X_test.groupby('qid')['qid'].count().to_numpy()\n",
        "\n",
        "        X_train = X_train.drop(['qid'], axis = 1)\n",
        "        X_test = X_test.drop(['qid'], axis = 1)\n",
        "\n",
        "        ranker.fit(\n",
        "            X=X_train,\n",
        "            y=y_train,\n",
        "            group=qids_train,\n",
        "            eval_set=[(X_test, y_test)],\n",
        "            eval_group=[qids_test],\n",
        "            eval_at=[1, 3, 5]\n",
        "        )\n",
        "\n",
        "        # Calculate NDCG score on the validation set\n",
        "        ndcg = ranker.best_score_['valid_0']['ndcg@5']\n",
        "        scores.append(ndcg)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "study = optuna.create_study(direction='maximize', study_name='LGBMRanker')\n",
        "func = lambda trial: objective(trial, X=X, y=y)\n",
        "study.optimize(func, n_trials=50)\n",
        "\n",
        "print('Best trial:')\n",
        "best_trial = study.best_trial\n",
        "print('NDCG: {}'.format(best_trial.value))\n",
        "print('Hyperparameters: {}'.format(best_trial.params))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WSV9iMzAX6ra"
      },
      "source": [
        "# Валидация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "NjgosavaTpbJ"
      },
      "outputs": [],
      "source": [
        "splitter = GroupShuffleSplit(test_size=0.2, n_splits=2, random_state=42)\n",
        "split = splitter.split(data, groups=data['text'])\n",
        "train_inds, val_inds = next(split)\n",
        "\n",
        "train = data.iloc[train_inds]\n",
        "val = data.iloc[val_inds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "5Z1rGPxrTpbK"
      },
      "outputs": [],
      "source": [
        "X_train_raw = train['text'] + train['comments_text']\n",
        "y_train = np.array(train['comments_score'])\n",
        "\n",
        "X_val_raw = val['text'] + val['comments_text']\n",
        "y_val = np.array(val['comments_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "3eQfA678UBzc"
      },
      "outputs": [],
      "source": [
        "embedding_name = embeddings_list[2][0]\n",
        "vector_dim = embeddings_list[2][1]\n",
        "\n",
        "best_embedding = gensim.downloader.load(embedding_name)\n",
        "best_tokenizer = NLTK_Tokenizer(delete_punctuation=True, delete_stop_words=True)\n",
        "\n",
        "train_emb = [text_to_vec(row, best_embedding, best_tokenizer, vector_dim) for row in X_train_raw]\n",
        "val_emb = [text_to_vec(row, best_embedding, best_tokenizer, vector_dim) for row in X_val_raw]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "UbnVfNltUbtE"
      },
      "outputs": [],
      "source": [
        "idx = []\n",
        "for i in range(int(len(train_emb) / 5)):\n",
        "    idx.extend([i] * 5)\n",
        "\n",
        "embeddings_df = pd.DataFrame(train_emb, columns=[i for i in range(1, vector_dim+1)])\n",
        "embeddings_df['score'] = y_train\n",
        "embeddings_df['qid'] = idx\n",
        "\n",
        "qids_train = embeddings_df.groupby('qid')['qid'].count().to_numpy()\n",
        "X = embeddings_df.drop(['score'], axis = 1)\n",
        "y = y_train\n",
        "\n",
        "splitter = GroupShuffleSplit(test_size=0.2, n_splits=2, random_state=42)\n",
        "split = splitter.split(X, y, groups=X['qid'])\n",
        "train_idx, test_idx = next(split)\n",
        "\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "qids_train = X_train.groupby('qid')['qid'].count().to_numpy()\n",
        "qids_test = X_test.groupby('qid')['qid'].count().to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "4gIScgNdTQRg",
        "outputId": "11c12b7b-a0e7-476f-ba00-1dc0fce78ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's ndcg@1: 0.541906\tvalid_0's ndcg@3: 0.656678\tvalid_0's ndcg@5: 0.823057\n",
            "[2]\tvalid_0's ndcg@1: 0.606689\tvalid_0's ndcg@3: 0.703323\tvalid_0's ndcg@5: 0.847909\n",
            "[3]\tvalid_0's ndcg@1: 0.625931\tvalid_0's ndcg@3: 0.715774\tvalid_0's ndcg@5: 0.855023\n",
            "[4]\tvalid_0's ndcg@1: 0.635082\tvalid_0's ndcg@3: 0.72265\tvalid_0's ndcg@5: 0.858352\n",
            "[5]\tvalid_0's ndcg@1: 0.635135\tvalid_0's ndcg@3: 0.725211\tvalid_0's ndcg@5: 0.858996\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.06518640195332566, metric=&#x27;ndcg&#x27;, n_estimators=5,\n",
              "           num_leaves=44, objective=&#x27;lambdarank&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(importance_type=&#x27;gain&#x27;, label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.06518640195332566, metric=&#x27;ndcg&#x27;, n_estimators=5,\n",
              "           num_leaves=44, objective=&#x27;lambdarank&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMRanker(importance_type='gain', label_gain=[0, 1, 2, 3, 4],\n",
              "           learning_rate=0.06518640195332566, metric='ndcg', n_estimators=5,\n",
              "           num_leaves=44, objective='lambdarank')"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyper = best_trial.params\n",
        "\n",
        "ranker = lightgbm.LGBMRanker(\n",
        "                    objective='lambdarank',\n",
        "                    boosting_type='gbdt',\n",
        "                    n_estimators=5,\n",
        "                    importance_type='gain',\n",
        "                    metric='ndcg',\n",
        "                    num_leaves=best_hyper['num_leaves'],\n",
        "                    learning_rate=best_hyper['learning_rate'],\n",
        "                    max_depth=best_hyper['max_depth'],\n",
        "                    label_gain=[i for i in range(max(y_train.max(), y_test.max()) + 1)])\n",
        "\n",
        "ranker.fit(\n",
        "      X=X_train,\n",
        "      y=y_train,\n",
        "      group=qids_train,\n",
        "      eval_set=[(X_test, y_test)],\n",
        "      eval_group=[qids_test],\n",
        "      eval_at=[1, 3, 5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "ki_YZSasUyvj"
      },
      "outputs": [],
      "source": [
        "idx = []\n",
        "for i in range(int(len(val_emb) / 5)):\n",
        "    idx.extend([i] * 5)\n",
        "\n",
        "val_embeddings_df = pd.DataFrame(val_emb, columns=[i for i in range(1, vector_dim+1)])\n",
        "val_embeddings_df['score'] = y_val\n",
        "val_embeddings_df['qid'] = idx\n",
        "\n",
        "qids_val = val_embeddings_df.groupby('qid')['qid'].count().to_numpy()\n",
        "X_val = val_embeddings_df.drop(['score'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQTzI4L0XIwc",
        "outputId": "925afc95-a250-408a-bd55-d64e27bb1da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAL ndcg@1: 0.6458345153664303\n",
            "VAL ndcg@3: 0.7296467874539512\n",
            "VAL ndcg@5: 0.8622997633192735\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "y_pred = ranker.predict(val_embeddings_df.drop(['score'], axis=1))\n",
        "y_pred = np.reshape(y_pred, (-1, 5))\n",
        "\n",
        "y_true = val_embeddings_df['score']\n",
        "y_true = np.reshape(y_true.values, (-1, 5))\n",
        "\n",
        "print('VAL ndcg@1:', ndcg_score(y_true, y_pred, k=1))\n",
        "print('VAL ndcg@3:', ndcg_score(y_true, y_pred, k=3))\n",
        "print('VAL ndcg@5:', ndcg_score(y_true, y_pred, k=5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Lbjc_lRYuUrZ",
        "9ZBMW_7rucjX",
        "YigeshWNue04",
        "3HC6EYoYuhZ2",
        "uubyHjjhuk_r",
        "nRGRKRm1unRV"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
